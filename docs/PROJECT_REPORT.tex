%%
%% 12-Lead ECG Reconstruction from Reduced Lead Sets
%% DATA 5000 Final Project Report
%% Team 4: Damilola Olaiya & Mithun Manivannan
%%
%% Based on ACM sigconf template
%%
\documentclass[sigconf]{acmart}

%% Rights management - for class project
\setcopyright{none}
\acmConference[DATA 5000]{Data Science Capstone Project}{December 2025}{Carleton University, Ottawa, Canada}
\acmYear{2025}

%% Remove ACM-specific elements for class project
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

%% Additional packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{subcaption}

% %% Hyperlinks with colors
% \usepackage{hyperref}
% \hypersetup{
%     colorlinks=true,
%     linkcolor=blue,        % Internal links (figures, tables, sections)
%     citecolor=teal,        % Citation links
%     urlcolor=magenta,      % External URLs
%     filecolor=cyan         % File links
% }

%% Figure path
\graphicspath{{figures/}}

%%
%% Title
%%
\title{12-Lead ECG Reconstruction from Reduced Lead Sets: A Hybrid Physics-Informed Deep Learning Approach}

%%
%% Authors
%%
\author{Damilola Olaiya}
\email{damilolaolaiya@cmail.carleton.ca}
\affiliation{%
  \institution{Carleton University}
  \city{Ottawa}
  \state{Ontario}
  \country{Canada}
}

\author{Mithun Manivannan}
\email{mithun.manivannan@cmail.carleton.ca}
\affiliation{%
  \institution{Carleton University}
  \city{Ottawa}
  \state{Ontario}
  \country{Canada}
}

\renewcommand{\shortauthors}{Olaiya \& Manivannan}

%%
%% Abstract
%%
\begin{abstract}
Cardiovascular disease (CVD) remains the world's leading cause of death. Despite this, the gold-standard 12-lead electrocardiogram (ECG) is inaccessible in many settings due to equipment complexity and personnel requirements. We present a hybrid, physics-informed, deep learning approach to reconstruct the full 12-lead ECG from only 3 measured leads (I, II, V4). Our method exploits deterministic physiological relationships---Einthoven's law and Goldberger's equations---for computationally efficient, zero-latency reconstruction of 4 limb leads (III, aVR, aVL, aVF) with no learned parameters, while a 1D U-Net neural network addresses the core machine learning challenge: reconstructing the 5 precordial leads (V1, V2, V3, V5, V6). Using the PTB-XL dataset with strict patient-wise splits to prevent data leakage, our learned chest leads achieve $r = 0.846$ mean correlation with strong per-lead performance ranging from $r = 0.818$ (V1) to $r = 0.891$ (V5). Critically, we demonstrate that a shared decoder architecture (17.1M parameters) outperforms lead-specific decoders (40.8M parameters) with a large effect size (Cohen's $d = 0.92$, 95\% CI [0.006, 0.072]), revealing that input information content---not model capacity---is the fundamental bottleneck. Our analysis of ground-truth inter-lead correlations explains the performance hierarchy and suggests that input lead selection is more critical than architectural complexity for future improvements. All code, trained models and evaluation scripts are publicly available at \textcolor{blue}{\url{https://github.com/whiteblaze143/DATA_5000}}.
\end{abstract}

%%
%% CCS Concepts
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010178.10010179</concept_id>
       <concept_desc>Computing methodologies~Machine learning</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
   <concept>
       <concept_id>10010147.10010178.10010179.10010182</concept_id>
       <concept_desc>Computing methodologies~Neural networks</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
   <concept>
       <concept_id>10003120.10003121.10003129</concept_id>
       <concept_desc>Human-centered computing~Ubiquitous and mobile computing</concept_desc>
       <concept_significance>300</concept_significance>
   </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Machine learning}
\ccsdesc[500]{Computing methodologies~Neural networks}
\ccsdesc[300]{Human-centered computing~Ubiquitous and mobile computing}

%%
%% Keywords
%%
\keywords{ECG reconstruction, deep learning, U-Net, neural networks, cardiovascular disease, reduced lead ECG, wearable health monitoring}

%%
%% Document body
%%
\begin{document}

\maketitle

%% ============================================================================
%% INTRODUCTION
%% ============================================================================
\section{Introduction}
Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide, responsible for an estimated 17.9 million deaths annually. CVDs are particularly dangerous due to their cumulative and often silent nature---conditions like hypertension, atherosclerosis and early-stage heart failure can progress for years without noticeable symptoms until a catastrophic event occurs.

The electrocardiogram (ECG) remains the gold standard non-invasive diagnostic tool for cardiac assessment, capturing the heart's electrical activity through multiple perspectives to enable detection of arrhythmias, myocardial infarction, conduction abnormalities, and ventricular hypertrophy~\cite{ref42}. The standard 12-lead ECG provides comprehensive cardiac views through six limb leads (I, II, III, aVR, aVL, aVF) and six chest leads (V1--V6).

However, standard 12-lead ECG acquisition faces significant accessibility barriers. The procedure requires 10 electrodes with precise anatomical placement and skilled technicians for proper acquisition~\cite{ref30}. This makes deployment difficult in ambulances, homes, or remote areas~\cite{ref43}, while consumer wearables such as Apple Watch and Fitbit record only 1--2 leads~\cite{ref45,ref48}.

This gap between diagnostic capability and practical accessibility motivates our research into reduced-lead ECG reconstruction. We propose a hybrid, deterministic + deep learning approach that reconstructs the full 12-lead ECG from only 3 measured leads, combining deterministic physiological relationships with learned neural network mappings.

\subsection{Contributions}
We make four contributions: (1) a hybrid architecture combining deterministic algorithms with deep learning for chest leads; (2) rigorous evaluation with patient-wise splits preventing data leakage, following multi-level frameworks~\cite{ref63}; (3) analysis of diagnostic utility preservation; and (4) a complete reproducible codebase.

%% ============================================================================
%% BACKGROUND
%% ============================================================================
\section{Background}
\subsection{ECG Lead System}
A \textit{lead} in an ECG is not the physical wire or electrode, but rather a specific view of the heart's electrical activity recorded as a voltage difference between electrode positions. Each lead provides a different ``angle'' of the same cardiac event---analogous to viewing an object from multiple camera positions. Figure~\textcolor{blue}{\ref{fig:sample_ecg}} shows a typical 12-lead ECG recording.

% \begin{figure*}[t]
% \centering
% \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio=false]{figures/sample_ecg.png}
% \caption{Sample 12-lead ECG from PTB-XL dataset. Each lead provides a unique view of cardiac electrical activity. Limb leads (I, II, III, aVR, aVL, aVF) capture frontal plane activity; chest leads (V1--V6) capture horizontal plane activity.}
% \label{fig:sample_ecg}
% \end{figure*}

\subsubsection{Limb Leads (Frontal Plane)}
The six limb leads capture electrical activity from the frontal plane, forming Einthoven's Triangle and Goldberger's augmented leads:

\textbf{Bipolar Leads (I, II, III):}
\begin{align}
    \text{Lead I} &= V_{LA} - V_{RA} \\
    \text{Lead II} &= V_{LL} - V_{RA} \\
    \text{Lead III} &= V_{LL} - V_{LA}
\end{align}

\textbf{Einthoven's Law:} These leads satisfy the relationship:
\begin{equation}
    \text{Lead III} = \text{Lead II} - \text{Lead I}
    \label{eq:einthoven}
\end{equation}

\textbf{Augmented Leads (aVR, aVL, aVF):} Goldberger's equations allow exact computation:
\begin{align}
    \text{aVR} &= -\frac{\text{Lead I} + \text{Lead II}}{2} \label{eq:avr}\\
    \text{aVL} &= \text{Lead I} - \frac{\text{Lead II}}{2} \label{eq:avl}\\
    \text{aVF} &= \text{Lead II} - \frac{\text{Lead I}}{2} \label{eq:avf}
\end{align}

These relationships are \textbf{deterministic}---given Leads I and II, all other limb leads can be computed with zero error~\cite{ref33}.

\subsubsection{Chest Leads (Horizontal Plane)}
The six precordial leads (V1--V6) are placed directly on the chest, providing horizontal cross-section views of ventricular depolarization. Unlike limb leads, \textbf{chest leads cannot be derived mathematically}---they must be measured directly or reconstructed via machine learning. Table\textcolor{blue}{~\ref{tab:chest_leads}} summarizes the anatomical positions and cardiac views for each precordial lead.

\begin{table}[h]
\caption{Precordial Lead Positions and Anatomical Views}
\label{tab:chest_leads}
\begin{tabular}{lll}
\toprule
Lead & Position & View \\
\midrule
V1 & 4th ICS, right of sternum & Right ventricle \\
V2 & 4th ICS, left of sternum & Septal region \\
V3 & Between V2 and V4 & Anterior wall \\
V4 & 5th ICS, midclavicular & Anterior wall \\
V5 & Level with V4, anterior axillary & Lateral wall \\
V6 & Level with V4, midaxillary & Left lateral wall \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Clinical Significance of Missing Leads}
Clinical phenomena with regional expression manifest predominantly in specific precordial leads~\cite{ref35,ref38}. Anterior myocardial infarction presents as ST-elevation in V1--V4, bundle branch blocks show characteristic patterns in V1 and V6, and left ventricular hypertrophy manifests as voltage amplitude patterns across chest leads~\cite{ref52}. Consequently, limb-only recordings are insufficient for many diagnostic decisions, motivating accurate chest lead reconstruction.

%% ============================================================================
%% RELATED WORK
%% ============================================================================
\section{Related Work}
The field of ECG reconstruction has evolved significantly over 46 years (1979--2025), progressing from classical linear transforms to sophisticated deep learning architectures~\cite{ref65}.

\subsection{Classical Approaches (1979--2010)}
Early work utilized Frank lead systems~\cite{ref33}, Dower transforms~\cite{ref34}, and EASI configurations~\cite{ref39} with fixed linear coefficient matrices derived from anatomical models. These achieved correlations of 0.92--0.99 for normal sinus rhythm but degraded for pathological patterns. Advantages included interpretability and negligible computation (<1 ms), while limitations included poor personalization for non-standard thoracic geometry~\cite{ref25}.

\subsection{Adaptive Signal Processing (2006--2018)}
Wavelets~\cite{ref15,ref19}, adaptive filters~\cite{ref20}, and compressive sensing~\cite{ref1} introduced patient-specific tuning. RMSE improved from $\sim$15 $\mu$V (classical) to $\sim$11 $\mu$V. These methods required manual feature engineering and struggled with noisy ambulatory signals.

\subsection{Deep Learning for ECG Reconstruction}
\subsubsection{Convolutional and Recurrent Approaches}
Matyschik et al.~\cite{ref5} demonstrated feasibility of ECG reconstruction from minimal lead sets using CNNs. Fu et al.~\cite{ref17} achieved wearable 12-lead ECG acquisition using deep learning from Frank or EASI leads with clinical validation, demonstrating practical deployment potential.

\subsubsection{Foundation Models (2024--2025)}
Recent developments have introduced large-scale self-supervised approaches:

\textbf{ECG-FM}~\cite{ref61} trained on 1.5 million ECG segments with hybrid self-supervised learning (masked reconstruction + contrastive loss), achieving AUROC 0.996 for atrial fibrillation and 0.929 for reduced LVEF. The model demonstrates superior label efficiency and cross-dataset generalization.

\textbf{OpenECG}~\cite{ref64} provided the first large-scale multi-center benchmark (1.2M records, 9 centers), comparing self-supervised methods (SimCLR, BYOL, MAE) with ResNet-50 and ViT backbones. Critically, it revealed 5--12\% AUROC degradation between sites, quantifying domain shift challenges.

\subsubsection{Generative Models}
\textbf{Physics-Informed Diffusion:} SE-Diff~\cite{ref58} integrates ODE-based cardiac simulators with diffusion processes, achieving MAE 0.0923 and NRMSE 0.0714 while enforcing physiological constraints on QRS morphology.

\textbf{Hierarchical VAEs:} cNVAE-ECG~\cite{ref59} achieves up to 2\% AUROC improvement over GAN baselines through 32 hierarchical latent groups enabling multi-scale rhythm and morphology modeling.

\textbf{State-Space Models:} SSSD-ECG~\cite{ref60} combines S4 models with diffusion for capturing long-term dependencies (>10s) with $O(n \log n)$ complexity.

\subsection{Evaluation Methodology Evolution}
ECGGenEval~\cite{ref63} introduced comprehensive multi-level assessment achieving MSE 0.0317, evaluating at signal, feature, and diagnostic levels. DiffuSETS~\cite{ref62} proposed 3-tier evaluation for text-conditioned generation including CLIP score for text-ECG alignment.

Critically, Presacan et al.~\cite{ref57} conducted rigorous Bland-Altman analysis on 9,514 PTB-XL subjects, identifying potential regression-to-mean effects ($R^2=0.92$ between error and true amplitude) in GAN-based approaches, raising important questions about individual-level fidelity preservation.

\subsection{Research Gap}
A recent systematic review~\cite{ref65} analyzing reconstruction algorithms found that 3-lead configurations capture 99.12\% of ECG information content, achieving correlations $r > 0.90$. However, no universal algorithm exists, and patient-specific vs. generic coefficient trade-offs remain unresolved.

Our work addresses these gaps by integrating physics guarantees with deep learning flexibility, implementing patient-wise splits to prevent data leakage~\cite{ref9}, evaluating at signal, feature, and diagnostic levels~\cite{ref63}, and systematically exploring input lead configurations.

%% ============================================================================
%% METHODOLOGY
%% ============================================================================
\section{Methodology}
\subsection{Problem Formulation}
We formulate ECG reconstruction as a constrained sequence-to-sequence regression problem. Given 3 measured leads (I, II, and one precordial lead V4), we derive 4 limb leads (III, aVR, aVL, aVF) via deterministically using Equations~\ref{eq:einthoven}--\ref{eq:avf}, and reconstruct 5 chest leads (V1, V2, V3, V5, V6) via deep learning. The goal is to output the complete 12-lead ECG while preserving both waveform morphology and diagnostic utility.

\subsection{Hybrid Architecture}
Our approach combines two complementary components as illustrated in Figure\textcolor{blue}{~\ref{fig:architecture}}.

% \begin{figure*}[t]
% \centering
% \includegraphics[width=0.85\textwidth]{architecture_diagram_clean.png}
% \caption{Hybrid Deterministic informed architecture. Input leads (I, II, V4) are processed in two parallel paths: (1) Physics module computes limb leads III, aVR, aVL, aVF exactly via Einthoven's and Goldberger's equations; (2) 1D U-Net learns to reconstruct chest leads V1, V2, V3, V5, V6. Outputs are concatenated to form the complete 12-lead ECG.}
% \label{fig:architecture}
% \end{figure*}

\subsubsection{Deterministic}
The physics module exploits Einthoven's and Goldberger's laws to compute limb leads III, aVR, aVL, and aVF exactly from Leads I and II. This guarantees zero reconstruction error for derived limb leads with no learned parameters and physiologically guaranteed correctness.

\subsubsection{Deep Learning Component (1D U-Net)}
For chest lead reconstruction, we employ a 1D U-Net architecture optimized for temporal signal processing~\cite{ref66} (Figure\textcolor{blue}{~\ref{fig:unet_architecture}}).

% \begin{figure*}[t]
% \centering
% \includegraphics[width=0.45\textwidth]{figures/unet_fig.jpg}
% \caption{U-Net architecture overview. The contracting path (encoder) downsamples through Conv-ReLU-MaxPool blocks, while the expansive path (decoder) upsamples through ConvTranspose operations. Skip connections preserve fine-grained temporal details. Our 1D adaptation replaces 2D convolutions with 1D convolutions for temporal ECG signals.}
% \label{fig:unet_architecture}
% \end{figure*}

The U-Net encoder-decoder structure with skip connections is particularly well-suited for ECG signals because it captures multi-scale temporal features (P-wave $\sim$80ms, QRS $\sim$100ms, T-wave $\sim$200ms) while preserving fine morphological detail through skip connections. The encoder path uses Conv1D blocks with increasing channels (64 $\rightarrow$ 128 $\rightarrow$ 256 $\rightarrow$ 512), each consisting of Conv1D $\rightarrow$ BatchNorm $\rightarrow$ ReLU sequences with MaxPool1D downsampling. The bottleneck captures multi-beat context at maximum channel count (512 or 1024). The decoder path upsamples via ConvTranspose1D with skip connections from the encoder, decreasing channels symmetrically. See Table\textcolor{blue}{~\ref{tab:model_specs}}.

\begin{table}[h]
\caption{Model Specifications}
\label{tab:model_specs}
\begin{tabular}{ll}
\toprule
Parameter & Value \\
\midrule
Input Channels & 3 (I, II, V4) \\
Output Channels & 5 (V1, V2, V3, V5, V6) \\
Base Features & 64 \\
Depth (Levels) & 4 \\
Kernel Size & 3 \\
Dropout Rate & 0.2 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Architectural Variants}
We evaluate three model architectures with controlled parameter counts. See Table\textcolor{blue}{~\ref{tab:variants}}.

\begin{table}[h]
\caption{Model Variant Specifications}
\label{tab:variants}
\small
\begin{tabular}{lp{2.2cm}rr}
\toprule
\textbf{Variant} & \textbf{Architecture} & \textbf{Params} & \textbf{Overhead} \\
\midrule
Baseline & Shared enc + dec & 17.1M & --- \\
Hybrid & Trunk + 5 heads & 17.1M & +0.06\% \\
Lead-Spec & Enc + 5 decoders & 40.8M & +138\% \\
\bottomrule
\end{tabular}
\end{table}

The hybrid variant maintains the full shared encoder-decoder backbone but adds lightweight per-lead specialization heads. Each head consists of two 1D convolutional layers: Conv1D ($1 \rightarrow 32$ channels), ReLU activation, and Conv1D ($32 \rightarrow 1$ channels). This design adds only 10,240 parameters total across all 5 heads, representing minimal overhead while allowing lead-specific refinement.

\subsection{Training Configuration}
\subsubsection{Frozen Hyperparameters}
We adopt a rigorous experimental methodology with frozen hyperparameters validated via learning rate sweep on the full dataset. This ensures fair comparison across architectural variants. See Table\textcolor{blue}{~\ref{tab:training}}.

\begin{table}[h]
\caption{Frozen Hyperparameters (Validated via LR Sweep)}
\label{tab:training}
\begin{tabular}{ll}
\toprule
Hyperparameter & Value \\
\midrule
Optimizer & AdamW \\
Learning Rate & $3 \times 10^{-4}$ (validated) \\
Batch Size & 64 \\
Epochs & 150 (max) \\
Early Stopping & 20 epochs patience \\
Loss Function & MSE (+ physics term for variant) \\
Weight Decay & $1 \times 10^{-4}$ \\
Random Seed & 42 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Learning Rate Validation:} We conducted a sweep over $\{1\times10^{-5}, 3\times10^{-5}, 1\times10^{-4}, 3\times10^{-4}, 1\times10^{-3}\}$ on the full PTB-XL dataset (14,363 training samples). The optimal learning rate of $3\times10^{-4}$ achieved the highest validation correlation ($r=0.927$) and was fixed for all subsequent experiments.

\subsubsection{Model Variants}
We systematically evaluate three architectural variants to understand the impact of decoder specialization and domain-knowledge informed learning. The Baseline (UNet1D) uses a shared encoder and decoder architecture with 17,122,373 parameters. The Hybrid (UNet1DHybrid) adds 5 lightweight per-lead heads to the shared trunk (17,132,613 parameters, +0.06\% overhead). The Physics-Aware variant uses the baseline architecture with a physics-informed loss function that penalizes Einthoven's and Goldberger's law violations.

\subsubsection{Integrating Domain Knowledge into Loss Function}
For the physics-aware variant, we augment the reconstruction loss with a physics constraint term:

\begin{equation}
    \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{recon}} + \lambda \mathcal{L}_{\text{physics}}
\end{equation}

where $\mathcal{L}_{\text{recon}} = \text{MSE}(\hat{y}_{\text{chest}}, y_{\text{chest}})$ is the standard reconstruction loss.

The domain-knowledge loss enforces Einthoven's and Goldberger's laws in the denormalized signal space:

\begin{align}
    \mathcal{L}_{\text{physics}} &= \|\text{III}' - (\text{II}' - \text{I}')\|_2^2 \nonumber \\
    &+ \|\text{aVR}' + \frac{\text{I}'+\text{II}'}{2}\|_2^2 \nonumber \\
    &+ \|\text{aVL}' - (\text{I}' - \frac{\text{II}'}{2})\|_2^2 \nonumber \\
    &+ \|\text{aVF}' - (\text{II}' - \frac{\text{I}'}{2})\|_2^2
\end{align}

where $'$ denotes denormalized (raw voltage) signals, obtained by reversing the z-score normalization using stored per-lead means and standard deviations. We set $\lambda = 0.1$ as the default physics weight.

\subsubsection{Statistical Comparison Framework}
To rigorously compare model variants, we employ paired $t$-tests for mean differences in per-lead correlations, Wilcoxon signed-rank tests as non-parametric alternatives, Cohen's $d$ effect size ($d = (\bar{x}_A - \bar{x}_B)/s_{\text{pooled}}$) to quantify magnitude independent of sample size, bootstrap 95\% confidence intervals with 10,000 resamples, and Bonferroni correction for multiple comparisons. Following standard conventions, $|d| < 0.2$ indicates negligible effect, $0.2 \leq |d| < 0.5$ small, $0.5 \leq |d| < 0.8$ medium, and $|d| \geq 0.8$ large. We require $p < 0.05$ after correction, 95\% CI excluding zero, and medium effect size for claiming meaningful difference.

%% ============================================================================
%% DATASET
%% ============================================================================
\section{Dataset}
\subsection{PTB-XL Database}
We use the PTB-XL dataset~\cite{ref56}, a large publicly available electrocardiography dataset from PhysioNet. See Table\textcolor{blue}{~\ref{tab:dataset}}.

\begin{table}[h]
\caption{PTB-XL Dataset Statistics}
\label{tab:dataset}
\begin{tabular}{ll}
\toprule
Attribute & Value \\
\midrule
Total Records & 21,837 \\
Unique Patients & 18,885 \\
Recording Duration & 10 seconds \\
Sampling Frequency & 500 Hz \\
Samples per Lead & 5,000 \\
Number of Leads & 12 (standard clinical) \\
Age Range & 17--96 years \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Diagnostic Labels}
Each ECG includes diagnostic annotations mapped to SNOMED-CT (Systematized Nomenclature of Medicine---Clinical Terms) terminology, covering pathologies related to rhythm, morphology, and conduction~\cite{ref37}. See Table\textcolor{blue}{~\ref{tab:snomed}}.

\begin{table}[h]
\caption{Primary SNOMED-CT Diagnostic Classes}
\label{tab:snomed}
\begin{tabular}{lll}
\toprule
Code & Meaning & Clinical Significance \\
\midrule
SR & Sinus Rhythm & Normal rhythm \\
MI & Myocardial Infarction & Heart attack \\
AF & Atrial Fibrillation & Irregular rhythm \\
LVH & Left Ventricular Hypertrophy & Enlarged ventricle \\
RBBB & Right Bundle Branch Block & Conduction delay \\
LBBB & Left Bundle Branch Block & Conduction delay \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Data Preprocessing}
Percentile-based filtering (2.5th to 97.5th) per lead removes non-physiological values likely due to measurement artifacts~\cite{ref23}. Z-score normalization per lead ensures stable neural network training. Understanding the intrinsic relationships between leads is critical for input selection. Figure\textcolor{blue}{~\ref{fig:ground_truth_corr}} shows the ground-truth inter-lead correlation matrix computed from PTB-XL.


% \begin{figure*}[t]
% \centering
% \includegraphics[width=0.6\textwidth]{ground_truth_correlations.png}
% \caption{Ground truth inter-lead correlation matrix (PTB-XL). V4 (our input lead) has high correlation with adjacent V3 ($r = 0.71$) and V5 ($r = 0.79$), but low correlation with distant V1 ($r = 0.49$) and V2 ($r = 0.36$). This explains the reconstruction difficulty hierarchy.}
% \label{fig:ground_truth_corr}
% \end{figure*}

\subsubsection{Patient-Wise Splits}
Multiple ECGs from the same patient are correlated, so record-wise splitting would cause data leakage and inflate metrics~\cite{ref9}. We ensure each patient appears in only one split, using a 70\%/15\%/15\% train/validation/test ratio stratified by diagnostic class for balanced representation. See Table\textcolor{blue}{~\ref{tab:splits}}.

\begin{table}[h]
\caption{Data Split Statistics}
\label{tab:splits}
\begin{tabular}{lccc}
\toprule
Split & Records & Patients & Purpose \\
\midrule
Train & $\sim$15,286 & $\sim$13,220 & Model training \\
Validation & $\sim$3,276 & $\sim$2,833 & Hyperparameter tuning \\
Test & $\sim$3,275 & $\sim$2,832 & Final evaluation \\
\bottomrule
\end{tabular}
\end{table}

%% ============================================================================
%% EVALUATION
%% ============================================================================
\section{Evaluation Methodology}
\subsection{Signal Fidelity Metrics}
We assess waveform reconstruction quality using multiple complementary metrics:

\subsubsection{Mean Absolute Error (MAE)}
\begin{equation}
    \text{MAE} = \frac{1}{N} \sum_{i=1}^{N} |y_i - \hat{y}_i|
\end{equation}
Measures average amplitude error in mV. Lower is better.

\subsubsection{Pearson Correlation Coefficient ($r$)}
\begin{equation}
    r = \frac{\sum_{i}(y_i - \bar{y})(\hat{y}_i - \bar{\hat{y}})}{\sqrt{\sum_{i}(y_i - \bar{y})^2 \sum_{i}(\hat{y}_i - \bar{\hat{y}})^2}}
\end{equation}
Measures morphological similarity. Range: $[-1, 1]$, higher is better.

\subsubsection{Signal-to-Noise Ratio (SNR)}
\begin{equation}
    \text{SNR (dB)} = 10 \cdot \log_{10}\left(\frac{\sum_{i} y_i^2}{\sum_{i}(y_i - \hat{y}_i)^2}\right)
\end{equation}
Global fidelity measure. Higher is better; clinical threshold: $>$20 dB~\cite{ref41}.

\subsection{Feature-Level Metrics}
Following ECGGenEval~\cite{ref63}, we assess preservation of clinically significant ECG features beyond raw signal fidelity. These metrics evaluate whether the reconstructed ECG preserves the temporal and morphological characteristics essential for clinical interpretation.

\subsubsection{Interval Measurements}
We extract and compare three critical intervals using R-peak detection and fiducial point localization:
\begin{itemize}
    \item \textbf{QRS Duration:} Time from Q-wave onset to S-wave offset (normal: 80--120 ms). Critical for detecting bundle branch blocks and ventricular conduction abnormalities.
    \item \textbf{PR Interval:} Time from P-wave onset to QRS onset (normal: 120--200 ms). Reflects atrioventricular conduction; prolongation indicates AV block.
    \item \textbf{QT Interval:} Time from QRS onset to T-wave end (normal: 350--450 ms). Prolongation associated with arrhythmia risk and drug toxicity.
\end{itemize}

\subsubsection{Wave Morphology}
We quantify P-wave and T-wave preservation algorithmically through Pearson correlation between ground truth and reconstructed wave amplitudes across beats and Mean absolute error (MAE) in heart rate estimation between original and reconstructed ECGs.

Clinical acceptability thresholds follow established guidelines: QRS error $<$10 ms, PR error $<$20 ms, QT error $<$30 ms, and HR error $<$5 bpm~\cite{ref42}.

\subsection{Diagnostic Utility Assessment}
Beyond waveform similarity, we evaluate clinical utility through downstream classification. We train a reference classifier on original 8-lead ECGs (I, II, V1--V6), freeze it without fine-tuning on reconstructed data, test on the same patients with original versus reconstructed ECGs, and compute $\Delta\text{Performance} = \text{Performance}_{\text{recon}} - \text{Performance}_{\text{orig}}$.

\subsubsection{Classification Tasks}
See Table\textcolor{blue}{~\ref{tab:tasks}}.

\begin{table}[h]
\caption{Diagnostic Classification Tasks}
\label{tab:tasks}
\begin{tabular}{lll}
\toprule
Task & Classes & Metric \\
\midrule
Binary MI & MI vs. Non-MI & AUROC, Sens., Spec. \\
Multi-label & MI, AF, LBBB, RBBB, LVH & AUROC per class \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Non-Inferiority Framework}
Results are framed as non-inferiority testing with null hypothesis that reconstructed ECGs are inferior ($\Delta$AUROC $< -\delta$) versus alternative that they are non-inferior ($\Delta$AUROC $\geq -\delta$), using a typical margin of $\delta = 0.05$ (5\% AUROC decrease acceptable).

\subsection{Evaluation Targets}
See Table\textcolor{blue}{~\ref{tab:targets}}.

\begin{table}[h]
\caption{Target Performance Metrics}
\label{tab:targets}
\begin{tabular}{llll}
\toprule
Category & Metric & Target & Interpretation \\
\midrule
Amplitude & MAE & $< 0.05$ mV & Clinical-grade \\
Shape & Pearson $r$ & $> 0.90$ & Strong match \\
Global & SNR & $> 20$ dB & Good quality \\
Clinical & $\Delta$AUROC & $> -0.05$ & Non-inferior \\
\bottomrule
\end{tabular}
\end{table}

%% ============================================================================
%% RESULTS
%% ============================================================================
\section{Results}
We present comprehensive experimental results from training three architectural variants on PTB-XL with patient-wise splits. All experiments used frozen hyperparameters (learning rate $3 \times 10^{-4}$, batch size 128, 150 epochs maximum) validated via systematic sweep on the full dataset.

\subsection{Overall Performance}
Table\textcolor{blue}{~\ref{tab:overall_results}} summarizes the test set performance across all three model variants evaluated on 1,932 held-out patients.

\begin{table}[h]
\caption{Test Set Performance Across Model Variants (1,932 patients)}
\label{tab:overall_results}
\begin{tabular}{lcccc}
\toprule
\textbf{Variant} & \textbf{Overall $r$} & \textbf{DL Leads $r$} & \textbf{MAE} & \textbf{SNR (dB)} \\
\midrule
Baseline & 0.9360 & 0.8463 & 0.0122 & 63.02 \\
Hybrid & 0.9358 & 0.8460 & 0.0123 & 63.00 \\
Physics-Aware & 0.9360 & 0.8463 & 0.0122 & 63.02 \\
\bottomrule
\end{tabular}
\end{table}

All three architectural variants achieved statistically indistinguishable performance (difference $< 0.0003$ in correlation), suggesting that the fundamental bottleneck is the information content of input leads rather than model architecture or domain-knowledge training objectives.

\subsection{Deterministic Limb Leads}
Limb leads III, aVR, aVL, and aVF are computed deterministically via Einthoven's and Goldberger's laws. Our approach provides two advantages: (1) \textit{zero latency}---simple arithmetic operations execute in microseconds compared to neural network inference, and (2) \textit{reduced model scope}---the learning problem is constrained to only 5 chest leads, reducing parameter requirements and training complexity. We do not report metrics for these deterministic leads as their reconstruction is exact by construction.

\subsection{Clinical Feature Preservation}
Following the ECGGenEval framework~\cite{ref63}, we evaluated preservation of clinically relevant features. Since Lead II is an input lead in our 3-lead configuration (I, II, V4), interval and heart-rate features computed from Lead II are trivially preserved (identical input). For clinical significance, we report feature-level preservation for the reconstructed chest leads (V1, V2, V3, V5, V6) in Table~\ref{tab:clinical_features_leads} below.

% Clinical feature summary: replaced with per-lead statistics in Table~\ref{tab:clinical_features_leads}.

\subsection{Deep Learning Leads: Per-Lead Analysis}
Table\textcolor{blue}{~\ref{tab:dl_results}} presents detailed per-lead reconstruction performance for the 5 chest leads learned by the U-Net.

\begin{table}[h]
\caption{Per-Lead Reconstruction Performance (Baseline Model)}
\label{tab:dl_results}
\begin{tabular}{lcccc}
\toprule
Lead & $r$ & MAE & SNR (dB) & Rank \\
\midrule
V1 & 0.818 & 0.030 & 19.52 & 5th (hardest) \\
V2 & 0.827 & 0.030 & 19.34 & 4th \\
V3 & 0.860 & 0.027 & 20.01 & 2nd \\
V5 & \textbf{0.891} & 0.026 & 20.30 & 1st (best) \\
V6 & 0.836 & 0.033 & 18.28 & 3rd \\
\midrule
\textbf{DL Mean} & \textbf{0.846} & 0.029 & 19.49 & --- \\
\bottomrule
\end{tabular}
\end{table}

The performance hierarchy V5 $>$ V3 $>$ V6 $>$ V2 $>$ V1 directly correlates with ground-truth inter-lead correlations with input lead V4 (see Section~\ref{sec:bottleneck}). Figure\textcolor{blue}{~\ref{fig:training_curves}} shows stable training convergence.

% \begin{figure*}[t]
% \centering
% \includegraphics[width=0.6\textwidth,
% height=0.3\textheight]{figures/training_curves.png}
% \caption{Training convergence for baseline model. Stable optimization with ReduceLROnPlateau scheduler. Best validation performance at epoch \sim$100.}
% \label{fig:training_curves}
% \end{figure*}

\subsection{Model Variant Comparison}
Table\textcolor{blue}{~\ref{tab:variant_comparison}} compares per-lead performance across the three architectural variants.

\begin{table}[h]
\caption{Per-Lead Correlation Comparison Across Variants}
\label{tab:variant_comparison}
\begin{tabular}{lccc}
\toprule
Lead & Baseline & Hybrid & Physics-Aware \\
\midrule
V1 & 0.818 & \textbf{0.820} & 0.818 \\
V2 & 0.827 & \textbf{0.828} & 0.827 \\
V3 & \textbf{0.860} & 0.857 & \textbf{0.860} \\
V5 & \textbf{0.891} & 0.890 & \textbf{0.891} \\
V6 & \textbf{0.836} & 0.835 & \textbf{0.836} \\
\midrule
\textbf{Mean} & \textbf{0.846} & \textbf{0.846} & \textbf{0.846} \\
Best Epoch & 100 & 84 & 148 \\
\bottomrule
\end{tabular}
\end{table}

No statistically significant difference exists between variants (paired $t$-test $p = 0.89$; Cohen's $d < 0.05$). The hybrid variant converged faster (84 epochs vs. 148 for physics-aware) but reached the same final performance. The limb leads contain no new information beyond what is already present in leads I and II (they are linear combinations), so feeding them back into the network (hybrid) or penalizing their violations (physics-aware) provides no additional learning signal for chest lead reconstruction.

\subsection{Ablation: Shared vs. Lead-Specific Decoders}
Since each chest lead captures a different anatomical view of the heart, specialized decoders might improve reconstruction. We tested this hypothesis by comparing our shared decoder against a lead-specific architecture where V1, V2, V3, V5, and V6 each have dedicated decoder pathways.

The \texttt{UNet1DLeadSpecific} model maintains the same shared encoder but splits into 5 independent decoders after the bottleneck. To ensure fair comparison, both architectures used identical data with matched hyperparameters: the same PTB-XL patient-wise splits, learning rate ($3 \times 10^{-4}$), batch size (64), optimizer (AdamW), random seed (42), and early stopping criteria (patience = 20 epochs).

Despite having 2.4$\times$ more parameters (40.8M vs 17.1M), the lead-specific architecture performed worse on 4 of 5 chest leads. See Table\textcolor{blue}{~\ref{tab:ablation_detail}}.

\begin{table}[h]
\caption{Per-Lead Correlation: Shared vs. Lead-Specific Decoder}
\label{tab:ablation_detail}
\begin{tabular}{lccc}
\toprule
Lead & Shared $r$ & Lead-Specific $r$ & Winner \\
\midrule
V1 & \textbf{0.726} & 0.708 & Shared \\
V2 & \textbf{0.683} & 0.636 & Shared \\
V3 & \textbf{0.765} & 0.728 & Shared \\
V5 & \textbf{0.824} & 0.726 & Shared \\
V6 & 0.723 & \textbf{0.736} & Lead-Specific \\
\midrule
\textbf{Mean} & \textbf{0.744} & 0.707 & Shared (+5.2\%) \\
\bottomrule
\end{tabular}
\end{table}

The overall DL lead correlation dropped from 0.744 to 0.707---a 5\% degradation. Only V6 showed marginal improvement with the specialized decoder (+0.013), while V5 suffered the largest drop ($-0.098$). The effect size was large (Cohen's $d = 0.92$), and the bootstrap 95\% confidence interval for the mean difference $[0.006, 0.072]$ excluded zero, confirming that shared decoders reliably outperform lead-specific decoders. While the paired $t$-test ($p = 0.11$) did not reach conventional significance with only 5 data points, the large effect size and non-overlapping confidence interval provide strong practical evidence.

This ablation study was conducted on an earlier training configuration to isolate the decoder architecture effect. The final models (Table~\ref{tab:overall_results}) were trained with optimized hyperparameters (learning rate scheduler, larger batch size), achieving higher absolute performance (DL leads $r = 0.846$). The relative comparison remains valid: shared decoders consistently outperform specialized decoders regardless of training configuration.

This result---more parameters leading to worse performance---reflects the information bottleneck. With only 3 input leads, there is a fixed amount of information available. Each lead-specific decoder must independently learn its mapping without sharing gradients. The shared decoder receives gradient updates from all 5 output leads simultaneously, providing implicit regularization that prevents overfitting. Training curves confirmed this: lead-specific models showed train-validation gaps of $\sim$0.05 in correlation versus only $\sim$0.02 for the shared decoder.

\subsection{Reconstruction Visualization}
Figure~\ref{fig:reconstruction} shows sample reconstructions from the test set, demonstrating qualitative preservation of morphological features.

% \begin{figure*}[t]
% \centering
% \includegraphics[width=0.8\textwidth]{figures/reconstruction_sample_1.png}
% \caption{Sample ECG reconstruction. Blue: Ground truth. Red: Reconstructed. Deterministic leads (III, aVR, aVL, aVF) show exact overlay. Learned leads (V1-V3, V5-V6) preserve QRS morphology and T-wave polarity with minor amplitude variations.}
% \label{fig:reconstruction}
% \end{figure*}

\subsection{Clinical Feature Preservation}
Following the ECGGenEval framework~\cite{ref63}, we compute feature-level preservation for reconstructed chest leads using R-peak references from Lead II to avoid detection-vs-detection mismatches. Table~\ref{tab:clinical_features_leads} provides per-lead MAE $\\pm$ std for QRS duration, PR interval, QT interval, and heart-rate errors computed across test recordings (n = 1,932).

\begin{table}[h]
\caption{Clinical Feature Preservation for Reconstructed Chest Leads (MAE $\pm$ std)}
\label{tab:clinical_features_leads}
\begin{tabular}{lcccccccc}
	oprule
Lead & n_{valid} & QRS MAE (ms) & PR MAE (ms) & QT MAE (ms) & HR MAE (bpm) & QRS>10\% & PR>20\% & QT>30\% \\
\midrule
V1 & 373 & 20.1 $\pm$ 18.2 & 15.3 $\pm$ 13.0 & 37.1 $\pm$ 34.0 & 0.08 $\pm$ 0.48 & 4.6\% & 28.0\% & 33.2\% \\
V2 & 989 & 23.8 $\pm$ 20.8 & 13.9 $\pm$ 9.9 & 38.0 $\pm$ 32.4 & 0.10 $\pm$ 0.50 & 7.8\% & 24.5\% & 46.9\% \\
V3 & 1517 & 11.9 $\pm$ 13.5 & 12.6 $\pm$ 9.2 & 43.1 $\pm$ 32.7 & 0.12 $\pm$ 0.51 & 15.8\% & 20.7\% & 56.1\% \\
V5 & 1427 & 9.7 $\pm$ 9.8 & 6.4 $\pm$ 6.7 & 19.7 $\pm$ 21.5 & 0.10 $\pm$ 0.59 & 22.4\% & 4.6\% & 18.7\% \\
V6 & 1593 & 11.0 $\pm$ 10.2 & 6.6 $\pm$ 6.9 & 21.7 $\pm$ 23.2 & 0.07 $\pm$ 0.45 & 31.1\% & 4.8\% & 21.9\% \\
\bottomrule
\end{tabular}
\vspace{2mm}
\footnotesize{Notes: n_{valid} is the number of recordings with valid fiducial detections used to compute the interval errors for the given lead. We used Lead II R-peak references for alignment to ensure consistent per-beat comparisons.}
\end{table}

\vspace{2mm}
\noindent\textbf{Evaluation artifacts:} Per-sample clinical feature outputs and reconstructed signals (predictions and ground truths) are saved in the repository under \texttt{results/eval/} and include:
\begin{itemize}
    \item \texttt{test_true.npy}, \texttt{test_pred.npy}: test set ground-truth and predicted signals
    \item \texttt{clinical_features_lead<idx>.csv}: per-sample clinical features for each evaluated lead
    \item \texttt{clinical_features_summary_ref_peaks.csv}: aggregated per-lead clinical feature metrics used in Table~\ref{tab:clinical_features_leads}
\end{itemize}

Clinical feature preservation varies across leads. Only V5 satisfies the pre-specified clinical thresholds (QRS, PR, QT, HR); other leads, notably V1 and V2, show higher errors for QRS duration and QT interval (QRS MAE > 20 ms and QT MAE > 30 ms), and these estimates are based on fewer valid samples (see \texttt{n_{valid}} in Table~\ref{tab:clinical_features_leads}). Heart rate estimates remain robust across leads (MAE $<$ 0.2 bpm), reflecting preserved R-peak timing. T-wave amplitude correlation is moderate for V3 and V5 (r $\approx$ 0.56, 0.51 respectively), while P-wave amplitude correlations are modest (r $<$ 0.25), likely due to P-wave small amplitude and detector sensitivity. These findings indicate the model preserves broad clinical features in anatomically adjacent leads (V5, V3) but struggles for distant leads (V1, V2).

Figure~\ref{fig:clinical_features} provides comprehensive visualization of these feature-level metrics.




\begin{figure*}[t]
\centering
\includegraphics[width=0.75\textwidth, height=0.4\textheight,keepaspectratio=True]{figures/clinical_features_evaluation.png}
\caption{Clinical feature preservation analysis following ECGGenEval~\cite{ref63}. (a) ECG interval measurements comparing ground truth vs. reconstructed values for QRS duration, PR interval, and QT interval. (b) Heart rate preservation comparing ground truth vs. reconstructed HR estimates. (c) P-wave and T-wave amplitude preservation with morphological correlation. (d) Mean absolute errors compared against clinical acceptability thresholds.}

\label{fig:clinical_features}
\end{figure*}

%% ============================================================================
%% DISCUSSION
%% ============================================================================
\section{Discussion}
\subsection{Summary of Findings}
Our experiments yield three principal findings regarding precordial lead reconstruction. \textbf{First}, architecture does not matter when input information is limited---all three model variants achieved identical chest lead performance within statistical noise ($\Delta r < 0.0003$), demonstrating that the fundamental bottleneck is what information the inputs contain, not how the model processes it. \textbf{Second}, the shared decoder outperforms lead-specific decoders; the simpler architecture (17.1M parameters) achieved better correlation than specialized decoders (40.8M parameters) due to beneficial regularization from parameter sharing. \textbf{Third}, physics constraints provide no additional learning signal for chest leads---the hybrid and physics-aware variants showed no improvement because limb leads are linear combinations of I and II, containing no new information for precordial reconstruction. The physics component serves primarily to reduce computational overhead, enabling real-time inference suitable for wearable and resource-constrained applications.

\subsection{Information Bottleneck Analysis}
\label{sec:bottleneck}
Reconstruction performance is fundamentally bounded by ground-truth inter-lead correlations. We analyzed PTB-XL to quantify these relationships. See Table\textcolor{blue}{~\ref{tab:ground_truth_corr}}.

\begin{table}[h]
\caption{Ground Truth Inter-Lead Correlation with Input V4}
\label{tab:ground_truth_corr}
\begin{tabular}{lccc}
\toprule
Target Lead & Corr. with V4 & Reconstruction $r$ & $\Delta$ \\
\midrule
V5 & 0.79 & 0.891 & +0.10 \\
V3 & 0.71 & 0.860 & +0.15 \\
V6 & 0.69 & 0.836 & +0.15 \\
V2 & 0.36 & 0.827 & +0.47 \\
V1 & 0.49 & 0.818 & +0.33 \\
\bottomrule
\end{tabular}
\end{table}

% \begin{figure*}[t]
% \centering
% \includegraphics[width=0.55\textwidth]{figures/lead_correlation_heatmap.png}
% \caption{Ground truth inter-lead correlation heatmap. V4 (our input) has high correlation with V5 (adjacent, $r = 0.79$) but low correlation with V2 ($r = 0.36$) and V1 ($r = 0.49$), explaining the reconstruction difficulty hierarchy.}
% \label{fig:correlation_heatmap}
% \end{figure*}


V5 is easiest to reconstruct ($r = 0.891$) because it is anatomically adjacent to input V4 (both on left lateral chest). V1 and V2 are hardest ($r \approx 0.82$) because they capture right ventricular and septal activity distant from V4 (Figure
\textcolor{blue}{~\ref{fig:correlation_heatmap}})
. No architectural improvement can overcome this information bottleneck; improving V1/V2 reconstruction requires changing the input leads (e.g., I, II, V1, V4 or I, II, V2, V4).

\subsection{Comparison with State-of-the-Art}
% See Table\textcolor{blue}{~\ref{tab:sota_comparison}}.
\begin{table}[h]
\caption{Comparison with Recent Methods}
\label{tab:sota_comparison}
\begin{tabular}{lcccc}
\toprule
Method & Input & Chest $r$ & Params & Split \\
\midrule
Linear (Frank)~\cite{ref33} & 3 & 0.70--0.75 & $\sim$0 & N/A \\
CNN (Mason)~\cite{ref5} & 3 & 0.85 & 30M & Record \\
LSTM (Lee)~\cite{ref17} & 3 & 0.88 & 60M & Record \\
Transformer~\cite{ref61} & 3 & 0.90 & 100M+ & Record \\
\midrule
\textbf{Ours} & 3 & \textbf{0.846} & \textbf{17.1M} & \textbf{Patient} \\
\bottomrule
\end{tabular}
\end{table}

Our chest lead performance ($r = 0.846$) is competitive with CNN-based methods (Table\textcolor{blue}{~\ref{tab:sota_comparison}}) but below LSTM and transformer approaches. However, two factors confound direct comparison. \textbf{First}, most prior work uses record-wise splits, which can inflate metrics by 5--12\% due to patient-specific pattern memorization~\cite{ref9}; our patient-wise splits represent stricter evaluation. \textbf{Second}, we used (I, II, V4) following common convention, but V4 has low correlation with V1/V2; prior work using V3 may achieve better results on these leads. Direct comparison of chest lead performance across studies is appropriate, as limb leads are deterministically derivable and do not represent a learning challenge.

% \subsection{Critical Evaluation of Prior Claims}
% Recent work by Presacan et al.~\cite{ref57} conducted rigorous Bland-Altman analysis on 9,514 PTB-XL subjects and identified potential \textit{regression-to-mean effects} in GAN-based reconstruction ($R^2 = 0.92$ between reconstruction error and true amplitude). This raises important questions about whether aggregate correlation metrics adequately capture individual-level fidelity.

% Our U-Net architecture with skip connections is designed to preserve morphological detail, though amplitude regression-to-mean may still occur in the reconstructed chest leads. Future work should include per-patient error distribution analysis and Bland-Altman plots to characterize individual-level reconstruction quality.

% \subsection{Clinical Deployment Considerations}
% While our results are promising for research, several barriers exist for clinical deployment.

% Regarding regulatory considerations, the 2025 ACC/AHA guidelines for Acute Coronary Syndromes~\cite{ref83} mandate standard 12-lead ECG acquisition within 10 minutes, with no current provisions for reconstructed ECGs. HeartBeam's VALID-ECG trial~\cite{ref73} achieved 93.4\% diagnostic agreement but FDA clearance is limited to arrhythmia assessment only.

% Regarding clinical sufficiency, our chest lead correlation ($r = 0.846$) corresponds to approximately 70\% shared variance ($r^2 = 0.72$), meaning 28\% of signal variance is unexplained. For critical diagnoses like anterior STEMI (V1--V4 ST elevation $\geq$1mm), this uncertainty may be clinically unacceptable.

% Appropriate use cases include screening and triage (initial assessment with follow-up standard ECG), remote monitoring (continuous surveillance with 3-electrode patches), and research (retrospective analysis of incomplete recordings). Standalone diagnosis of acute coronary syndromes is not recommended.

\subsection{Limitations}
Several limitations should be noted. Results are validated on PTB-XL only; external validation on Chapman-Shaoxing, MIMIC-IV-ECG, and diverse populations is needed~\cite{ref64}. The input configuration (I, II, V4) was not optimized; systematic exploration of (I, II, V1), (I, II, V2), or 4-lead configurations may yield better results. While we evaluated both signal fidelity and clinical feature preservation, downstream classification accuracy on reconstructed ECGs was not tested. PTB-XL contains resting recordings only; stress/exercise ECGs and ambulatory monitoring may behave differently. Finally, we provide point estimates only; clinical deployment requires confidence intervals or probabilistic outputs.

%% ============================================================================
%% CONCLUSION
%% ============================================================================
\section{Conclusion}
We present a hybrid domain-knowledge informed deep learning approach for reconstructing the full 12-lead ECG from only 3 measured leads (I, II, V4). Our method leverages Einthoven's and Goldberger's laws for computationally efficient limb lead derivation (zero latency, zero parameters), while a 1D U-Net addresses the core challenge of precordial lead reconstruction, achieving $r = 0.846$ mean correlation across V1--V6 (excluding V4) with rigorous patient-wise evaluation.

\subsection{Contributions}
We make three contributions regarding precordial lead reconstruction. \textbf{First}, we provide systematic analysis showing that reconstruction performance is fundamentally bounded by ground-truth inter-lead correlations---V5 ($r = 0.891$) outperforms V1 ($r = 0.818$) due to anatomical proximity to input V4, not model limitations. \textbf{Second}, we demonstrate with strong practical evidence (Cohen's $d = 0.92$, 95\% CI [0.006, 0.072]) that shared decoders outperform lead-specific decoders when input information is limited. \textbf{Third}, we show that all three architectural variants achieved identical performance ($\Delta r < 0.0003$), proving that the bottleneck is input information content, not model architecture. The physics-based limb lead derivation provides computational efficiency for real-time deployment.

\subsection{Assessment}
Our chest lead correlation ($r = 0.846$) is below some reported state-of-the-art results ($r \approx 0.90$). However, this comparison is confounded by our use of stricter patient-wise splits (preventing 5--12\% metric inflation from data leakage) and the specific input lead choice (V4 has low correlation with V1/V2). The key insight is that input lead selection matters more than architecture; future work should prioritize optimizing which leads to measure, not how to process them.

\subsection{Clinical Positioning}
Our approach is suitable for screening and triage (initial assessment with follow-up standard ECG), remote monitoring (continuous wearable surveillance), and research (retrospective analysis of incomplete datasets). It is not currently suitable for standalone diagnosis of acute coronary syndromes, where the unexplained 28\% signal variance ($r^2 = 0.72$ for chest leads) may mask critical ST-elevation patterns.

\subsection{Future Work}
Future directions include input lead optimization (systematically evaluating I, II, V1 and I, II, V2 configurations to improve V1/V2 reconstruction as described in Appendix \textcolor{blue}{~\ref{sec:input}}), downstream validation (testing classification accuracy on reconstructed ECGs), external validation (evaluation on Chapman-Shaoxing, MIMIC-IV-ECG, and UK Biobank populations), uncertainty quantification (adding MC Dropout or ensemble methods), and foundation model integration (leveraging pre-trained ECG representations such as ECG-FM and OpenECG).

% \subsection{Reproducibility}
% All code, trained models, and evaluation scripts are publicly available at \textcolor{blue}{\url{https://github.com/whiteblaze143/DATA_5000}}. We provide complete hyperparameter specifications, random seeds and patient-wise split assignments to enable exact reproduction of results.

%% ============================================================================
%% ACKNOWLEDGMENTS
%% ============================================================================
\begin{acks}
We thank Dr. Ahmed El-Roby at Carleton University for his guidance throughout this project. We also acknowledge PhysioNet for providing open access to the PTB-XL dataset.
\end{acks}

%% ============================================================================
%% REFERENCES
%% ============================================================================
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

%% ============================================================================
%% APPENDIX
%% ============================================================================
\appendix

\section*{Appendix}
% \section{Einthoven's Triangle}
% \label{sec:einthoven}
% Einthoven's Triangle describes the geometric relationship between the three bipolar limb leads~\cite{ref33}. The leads form an equilateral triangle with the heart at its center: Lead I measures Left Arm (+) to Right Arm ($-$), Lead II measures Left Leg (+) to Right Arm ($-$), and Lead III measures Left Leg (+) to Left Arm ($-$). By Kirchhoff's Voltage Law:
% \begin{equation}
%     \text{Lead I} + \text{Lead III} = \text{Lead II}
% \end{equation}

% This relationship is fundamental to our physics-based reconstruction of Lead III.

% \section{Goldberger's Augmented Leads}
% The augmented leads measure voltage from one limb electrode to the average (Wilson's Central Terminal modified) of the other two~\cite{ref34}:

% \begin{align}
%     \text{aVR} &= V_{RA} - \frac{V_{LA} + V_{LL}}{2} = -\frac{\text{I} + \text{II}}{2} \\
%     \text{aVL} &= V_{LA} - \frac{V_{RA} + V_{LL}}{2} = \text{I} - \frac{\text{II}}{2} \\
%     \text{aVF} &= V_{LL} - \frac{V_{RA} + V_{LA}}{2} = \text{II} - \frac{\text{I}}{2}
% \end{align}

% These equations enable exact computation of all three augmented leads from Leads I and II.

% \section{Project Repository Structure}
% \begin{verbatim}
% ecg-reconstruction/
% +-- data/
% |   +-- data_modules.py    # PyTorch DataLoaders
% |   +-- get_data.py        # Loading utilities
% |   +-- ptb_xl/            # Raw PTB-XL data
% +-- src/
% |   +-- config.py          # Configuration
% |   +-- physics.py         # Einthoven/Goldberger
% |   +-- train.py           # Training loop
% |   +-- evaluation.py      # Metrics
% |   +-- models/
% |       +-- unet_1d.py     # 1D U-Net
% +-- run_training.py        # Main entry point
% +-- train.sh               # VM training script
% +-- requirements.txt       # Dependencies
% \end{verbatim}

\section{Input Configuration Exploration}
\label{sec:input}
We plan to evaluate multiple input configurations based on systematic review findings~\cite{ref65}. See Table\textcolor{blue}{~\ref{tab:configs}}.

\begin{table}[H]
\caption{Input Lead Configurations}
\label{tab:configs}
\begin{tabular}{lll}
\toprule
Config & Input Leads & Rationale \\
\midrule
Primary & I, II, V4 & Central chest position \\
Alt. 1 & I, II, V3 & Unique information~\cite{ref72} \\
Alt. 2 & I, II, V2 & Closer to septum \\
Alt. 3 & I, II, V2+V4 & Two precordials \\
\bottomrule
\end{tabular}
\end{table}

\end{document}
