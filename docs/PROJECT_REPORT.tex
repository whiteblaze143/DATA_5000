%%
%% 12-Lead ECG Reconstruction from Reduced Lead Sets
%% DATA 5000 Final Project Report
%% Team 4: Damilola Olaiya & Mithun Mani
%%
%% Based on ACM sigconf template
%%
\documentclass[sigconf]{acmart}

%% Rights management - for class project
\setcopyright{none}
\acmConference[DATA 5000]{Data Science Capstone Project}{December 2025}{Carleton University, Ottawa, Canada}
\acmYear{2025}

%% Remove ACM-specific elements for class project
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

%% Additional packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{subcaption}

%% Figure path
\graphicspath{{figures/}}

%%
%% Title
%%
\title{12-Lead ECG Reconstruction from Reduced Lead Sets: A Hybrid Physics-Informed Deep Learning Approach}

%%
%% Authors
%%
\author{Damilola Olaiya}
\email{damilolaolaiya@cmail.carleton.ca}
\affiliation{%
  \institution{Carleton University}
  \city{Ottawa}
  \state{Ontario}
  \country{Canada}
}

\author{Mithun Mani}
\email{mithunmani@cmail.carleton.ca}
\affiliation{%
  \institution{Carleton University}
  \city{Ottawa}
  \state{Ontario}
  \country{Canada}
}

\renewcommand{\shortauthors}{Olaiya \& Mani}

%%
%% Abstract
%%
\begin{abstract}
Cardiovascular disease (CVD) remains the world's leading cause of death, yet the gold-standard 12-lead electrocardiogram (ECG) is inaccessible in many settings due to equipment complexity and personnel requirements. We present a hybrid physics-informed deep learning approach to reconstruct the full 12-lead ECG from only 3 measured leads (I, II, V4). Our method exploits deterministic physiological relationships---Einthoven's law and Goldberger's equations---for \textit{exact} reconstruction of 4 limb leads (III, aVR, aVL, aVF) with zero learned parameters, while a 1D U-Net neural network reconstructs the 5 remaining chest leads (V1, V2, V3, V5, V6). Using the PTB-XL dataset with strict patient-wise splits to prevent data leakage, we achieve an overall 12-lead correlation of $r = 0.936$, with physics-derived leads achieving perfect reconstruction ($r = 1.000$) and learned chest leads achieving $r = 0.846$. Critically, we demonstrate that a shared decoder architecture (17.1M parameters) outperforms lead-specific decoders (40.8M parameters) with statistical significance (Cohen's $d = 0.92$, $p < 0.001$), revealing that input information content---not model capacity---is the fundamental bottleneck. Our analysis of ground-truth inter-lead correlations explains the performance hierarchy (V5: $r = 0.891$ vs. V1: $r = 0.818$) and suggests that input lead selection is more critical than architectural complexity for future improvements.
\end{abstract}

%%
%% CCS Concepts
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010178.10010179</concept_id>
       <concept_desc>Computing methodologies~Machine learning</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
   <concept>
       <concept_id>10010147.10010178.10010179.10010182</concept_id>
       <concept_desc>Computing methodologies~Neural networks</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
   <concept>
       <concept_id>10003120.10003121.10003129</concept_id>
       <concept_desc>Human-centered computing~Ubiquitous and mobile computing</concept_desc>
       <concept_significance>300</concept_significance>
   </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Machine learning}
\ccsdesc[500]{Computing methodologies~Neural networks}
\ccsdesc[300]{Human-centered computing~Ubiquitous and mobile computing}

%%
%% Keywords
%%
\keywords{ECG reconstruction, deep learning, U-Net, physics-informed neural networks, cardiovascular disease, reduced lead ECG, wearable health monitoring}

%%
%% Document body
%%
\begin{document}

\maketitle

%% ============================================================================
%% INTRODUCTION
%% ============================================================================
\section{Introduction}

Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide, responsible for an estimated 17.9 million deaths annually. What makes CVDs particularly dangerous is their cumulative and often silent nature---conditions like hypertension, atherosclerosis, and early-stage heart failure can progress for years without noticeable symptoms until a catastrophic event occurs.

The electrocardiogram (ECG) remains the gold standard non-invasive diagnostic tool for cardiac assessment, capturing the heart's electrical activity through multiple perspectives to enable detection of arrhythmias, myocardial infarction, conduction abnormalities, and ventricular hypertrophy~\cite{ref42}. The standard 12-lead ECG provides comprehensive cardiac views through six limb leads (I, II, III, aVR, aVL, aVF) and six chest leads (V1--V6).

However, standard 12-lead ECG acquisition faces significant accessibility barriers:
\begin{itemize}
    \item \textbf{Equipment complexity:} Requires 10 electrodes with precise anatomical placement
    \item \textbf{Training requirements:} Needs skilled technicians for proper acquisition~\cite{ref30}
    \item \textbf{Setting limitations:} Difficult in ambulances, homes, or remote areas~\cite{ref43}
    \item \textbf{Consumer devices:} Wearables (Apple Watch, Fitbit) record only 1--2 leads~\cite{ref45,ref48}
\end{itemize}

This gap between diagnostic capability and practical accessibility motivates our research into reduced-lead ECG reconstruction. We propose a \textbf{hybrid physics-informed deep learning approach} that reconstructs the full 12-lead ECG from only 3 measured leads, combining deterministic physiological relationships with learned neural network mappings.

\begin{figure}[h]
\centering
\includegraphics[width=0.95\columnwidth]{approach_diagram.png}
\caption{Overview of our hybrid reconstruction approach. From 3 measured leads (I, II, V4), we reconstruct the full 12-lead ECG by exploiting known physics for limb leads and learning the mapping for chest leads.}
\label{fig:approach_overview}
\end{figure}

\subsection{Contributions}

Our main contributions are:
\begin{enumerate}
    \item \textbf{Hybrid Architecture:} A novel combination of physics-based exact derivation for limb leads and deep learning for chest lead reconstruction
    \item \textbf{Rigorous Evaluation:} Patient-wise data splits preventing leakage, with comprehensive signal fidelity and diagnostic utility assessment following multi-level evaluation frameworks~\cite{ref63}
    \item \textbf{Clinical Focus:} Multi-label classification evaluation ensuring preserved diagnostic capability
    \item \textbf{Reproducible Framework:} Complete codebase for reproducible research
\end{enumerate}

%% ============================================================================
%% BACKGROUND
%% ============================================================================
\section{Background}

\subsection{ECG Lead System}

A \textit{lead} in an ECG is not the physical wire or electrode, but rather a specific view of the heart's electrical activity recorded as a voltage difference between electrode positions. Each lead provides a different ``angle'' of the same cardiac event---analogous to viewing an object from multiple camera positions. Figure~\ref{fig:sample_ecg} shows a typical 12-lead ECG recording.

\begin{figure}[h]
\centering
\includegraphics[width=0.95\columnwidth]{sample_ecg.png}
\caption{Sample 12-lead ECG from PTB-XL dataset. Each lead provides a unique view of cardiac electrical activity. Limb leads (I, II, III, aVR, aVL, aVF) capture frontal plane activity; chest leads (V1--V6) capture horizontal plane activity.}
\label{fig:sample_ecg}
\end{figure}

\subsubsection{Limb Leads (Frontal Plane)}

The six limb leads capture electrical activity from the frontal plane, forming Einthoven's Triangle and Goldberger's augmented leads:

\textbf{Bipolar Leads (I, II, III):}
\begin{align}
    \text{Lead I} &= V_{LA} - V_{RA} \\
    \text{Lead II} &= V_{LL} - V_{RA} \\
    \text{Lead III} &= V_{LL} - V_{LA}
\end{align}

\textbf{Einthoven's Law:} These leads satisfy the relationship:
\begin{equation}
    \text{Lead III} = \text{Lead II} - \text{Lead I}
    \label{eq:einthoven}
\end{equation}

\textbf{Augmented Leads (aVR, aVL, aVF):} Goldberger's equations allow exact computation:
\begin{align}
    \text{aVR} &= -\frac{\text{Lead I} + \text{Lead II}}{2} \label{eq:avr}\\
    \text{aVL} &= \text{Lead I} - \frac{\text{Lead II}}{2} \label{eq:avl}\\
    \text{aVF} &= \text{Lead II} - \frac{\text{Lead I}}{2} \label{eq:avf}
\end{align}

These relationships are \textbf{deterministic}---given Leads I and II, all other limb leads can be computed with zero error~\cite{ref33}.

\subsubsection{Chest Leads (Horizontal Plane)}

The six precordial leads (V1--V6) are placed directly on the chest, providing horizontal cross-section views of ventricular depolarization. Unlike limb leads, \textbf{chest leads cannot be derived mathematically}---they must be measured directly or reconstructed via machine learning.

\begin{table}[h]
\caption{Precordial Lead Positions and Anatomical Views}
\label{tab:chest_leads}
\begin{tabular}{lll}
\toprule
Lead & Position & View \\
\midrule
V1 & 4th ICS, right of sternum & Right ventricle \\
V2 & 4th ICS, left of sternum & Septal region \\
V3 & Between V2 and V4 & Anterior wall \\
V4 & 5th ICS, midclavicular & Anterior wall \\
V5 & Level with V4, anterior axillary & Lateral wall \\
V6 & Level with V4, midaxillary & Left lateral wall \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Clinical Significance of Missing Leads}

Clinical phenomena with regional expression manifest predominantly in specific precordial leads~\cite{ref35,ref38}:

\begin{itemize}
    \item \textbf{Anterior MI:} ST-elevation in V1--V4
    \item \textbf{Bundle Branch Blocks:} Characteristic patterns in V1 and V6
    \item \textbf{Left Ventricular Hypertrophy:} Voltage amplitude patterns across chest leads~\cite{ref52}
\end{itemize}

Consequently, limb-only recordings are insufficient for many diagnostic decisions, motivating the need for accurate chest lead reconstruction.

%% ============================================================================
%% RELATED WORK
%% ============================================================================
\section{Related Work}

The field of ECG reconstruction has evolved significantly over 46 years (1979--2025), progressing from classical linear transforms to sophisticated deep learning architectures~\cite{ref65}.

\subsection{Classical Approaches (1979--2010)}

Early work utilized Frank lead systems~\cite{ref33}, Dower transforms~\cite{ref34}, and EASI configurations~\cite{ref39} with fixed linear coefficient matrices derived from anatomical models. These achieved correlations of 0.92--0.99 for normal sinus rhythm but degraded for pathological patterns. Advantages included interpretability and negligible computation (<1 ms), while limitations included poor personalization for non-standard thoracic geometry~\cite{ref25}.

\subsection{Adaptive Signal Processing (2006--2018)}

Wavelets~\cite{ref15,ref19}, adaptive filters~\cite{ref20}, and compressive sensing~\cite{ref1} introduced patient-specific tuning. RMSE improved from $\sim$15 $\mu$V (classical) to $\sim$11 $\mu$V. These methods required manual feature engineering and struggled with noisy ambulatory signals.

\subsection{Deep Learning for ECG Reconstruction}

\subsubsection{Convolutional and Recurrent Approaches}

Matyschik et al.~\cite{ref5} demonstrated feasibility of ECG reconstruction from minimal lead sets using CNNs. Fu et al.~\cite{ref17} achieved wearable 12-lead ECG acquisition using deep learning from Frank or EASI leads with clinical validation, demonstrating practical deployment potential.

\subsubsection{Foundation Models (2024--2025)}

Recent developments have introduced large-scale self-supervised approaches:

\textbf{ECG-FM}~\cite{ref61} trained on 1.5 million ECG segments with hybrid self-supervised learning (masked reconstruction + contrastive loss), achieving AUROC 0.996 for atrial fibrillation and 0.929 for reduced LVEF. The model demonstrates superior label efficiency and cross-dataset generalization.

\textbf{OpenECG}~\cite{ref64} provided the first large-scale multi-center benchmark (1.2M records, 9 centers), comparing self-supervised methods (SimCLR, BYOL, MAE) with ResNet-50 and ViT backbones. Critically, it revealed 5--12\% AUROC degradation between sites, quantifying domain shift challenges.

\subsubsection{Generative Models}

\textbf{Physics-Informed Diffusion:} SE-Diff~\cite{ref58} integrates ODE-based cardiac simulators with diffusion processes, achieving MAE 0.0923 and NRMSE 0.0714 while enforcing physiological constraints on QRS morphology.

\textbf{Hierarchical VAEs:} cNVAE-ECG~\cite{ref59} achieves up to 2\% AUROC improvement over GAN baselines through 32 hierarchical latent groups enabling multi-scale rhythm and morphology modeling.

\textbf{State-Space Models:} SSSD-ECG~\cite{ref60} combines S4 models with diffusion for capturing long-term dependencies (>10s) with $O(n \log n)$ complexity.

\subsection{Evaluation Methodology Evolution}

ECGGenEval~\cite{ref63} introduced comprehensive multi-level assessment achieving MSE 0.0317, evaluating at signal, feature, and diagnostic levels. DiffuSETS~\cite{ref62} proposed 3-tier evaluation for text-conditioned generation including CLIP score for text-ECG alignment.

Critically, Presacan et al.~\cite{ref57} conducted rigorous Bland-Altman analysis on 9,514 PTB-XL subjects, identifying potential regression-to-mean effects ($R^2=0.92$ between error and true amplitude) in GAN-based approaches, raising important questions about individual-level fidelity preservation.

\subsection{Research Gap}

A recent systematic review~\cite{ref65} analyzing reconstruction algorithms found that 3-lead configurations capture 99.12\% of ECG information content, achieving correlations $r > 0.90$. However, no universal algorithm exists, and patient-specific vs. generic coefficient trade-offs remain unresolved.

Our work addresses gaps by:
\begin{itemize}
    \item Integrating physics guarantees with deep learning flexibility
    \item Implementing patient-wise splits preventing data leakage~\cite{ref9}
    \item Evaluating multi-level metrics (signal + feature + diagnostic)~\cite{ref63}
    \item Exploring multiple input lead configurations systematically
\end{itemize}

\begin{table}[h]
\caption{Comparison with Prior Approaches}
\label{tab:comparison}
\begin{tabular}{lcc}
\toprule
Aspect & Prior Work & Our Approach \\
\midrule
Physics integration & Rare & Yes (limb leads) \\
Data split & Often record-wise & Patient-wise \\
Evaluation & Single-level & Multi-level \\
Input configurations & Single & Multiple explored \\
\bottomrule
\end{tabular}
\end{table}

%% ============================================================================
%% METHODOLOGY
%% ============================================================================
\section{Methodology}

\subsection{Problem Formulation}

We formulate ECG reconstruction as a \textbf{constrained sequence-to-sequence regression} problem:

\textbf{Input:} 3 measured leads
\begin{itemize}
    \item Lead I (limb)
    \item Lead II (limb)
    \item 1 precordial lead (V4 in primary configuration)
\end{itemize}

\textbf{Derived via Physics:} 4 limb leads (III, aVR, aVL, aVF) using Equations~\ref{eq:einthoven}--\ref{eq:avf}

\textbf{Reconstructed via Deep Learning:} 5 chest leads (V1, V2, V3, V5, V6)

\textbf{Output:} Complete 12-lead ECG

\textbf{Goal:} Preserve both waveform morphology AND diagnostic utility

\subsection{Hybrid Architecture}

Our approach combines two complementary components as illustrated in Figure~\ref{fig:architecture}.

\begin{figure}[h]
\centering
\includegraphics[width=0.95\columnwidth]{architecture_diagram_clean.png}
\caption{Hybrid physics-informed architecture. Input leads (I, II, V4) are processed in two parallel paths: (1) Physics module computes limb leads III, aVR, aVL, aVF exactly via Einthoven's and Goldberger's equations; (2) 1D U-Net learns to reconstruct chest leads V1, V2, V3, V5, V6. Outputs are concatenated to form the complete 12-lead ECG.}
\label{fig:architecture}
\end{figure}

\subsubsection{Physics Component (Deterministic)}

The physics module exploits Einthoven's and Goldberger's laws to compute limb leads III, aVR, aVL, and aVF exactly from Leads I and II. This guarantees:
\begin{itemize}
    \item Zero reconstruction error for derived limb leads
    \item No learned parameters required
    \item Physiologically guaranteed correctness
\end{itemize}

\subsubsection{Deep Learning Component (1D U-Net)}

For chest lead reconstruction, we employ a 1D U-Net architecture optimized for temporal signal processing~\cite{ref66}. The U-Net encoder-decoder structure with skip connections is particularly well-suited for ECG signals because it captures multi-scale temporal features (P-wave $\sim$80ms, QRS $\sim$100ms, T-wave $\sim$200ms) while preserving fine morphological detail through skip connections.

\textbf{Encoder Path:}
\begin{itemize}
    \item Conv1D blocks with increasing channels: 64 $\rightarrow$ 128 $\rightarrow$ 256 $\rightarrow$ 512
    \item Each block: Conv1D $\rightarrow$ BatchNorm $\rightarrow$ ReLU $\rightarrow$ Conv1D $\rightarrow$ BatchNorm $\rightarrow$ ReLU
    \item MaxPool1D (kernel=2) for downsampling
\end{itemize}

\textbf{Bottleneck:}
\begin{itemize}
    \item Maximum channel count (512 or 1024)
    \item Largest receptive field---captures multi-beat context
\end{itemize}

\textbf{Decoder Path:}
\begin{itemize}
    \item ConvTranspose1D for upsampling
    \item Skip connections from encoder (concatenation)
    \item Channels decrease: 512 $\rightarrow$ 256 $\rightarrow$ 128 $\rightarrow$ 64
\end{itemize}

\begin{table}[h]
\caption{Model Specifications}
\label{tab:model_specs}
\begin{tabular}{ll}
\toprule
Parameter & Value \\
\midrule
Input Channels & 3 (I, II, V4) \\
Output Channels & 5 (V1, V2, V3, V5, V6) \\
Base Features & 64 \\
Depth (Levels) & 4 \\
Kernel Size & 3 \\
Dropout Rate & 0.2 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Architectural Variants}

We evaluate three model architectures with controlled parameter counts:

\begin{table}[h]
\caption{Model Variant Specifications}
\label{tab:variants}
\begin{tabular}{lccc}
\toprule
\textbf{Variant} & \textbf{Architecture} & \textbf{Parameters} & \textbf{Overhead} \\
\midrule
Baseline (UNet1D) & Shared encoder + decoder & 17,122,373 & --- \\
Hybrid (UNet1DHybrid) & Shared trunk + 5 heads & 17,132,613 & +0.06\% \\
Lead-Specific & Shared encoder + 5 decoders & 40,831,237 & +138\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Hybrid Architecture (UNet1DHybrid):} The hybrid variant maintains the full shared encoder-decoder backbone (identical to baseline) but adds lightweight per-lead specialization heads. Each head consists of two 1D convolutional layers with ReLU activation:

\begin{itemize}
    \item Conv1D: $1 \rightarrow 32$ channels (hidden dimension)
    \item ReLU activation
    \item Conv1D: $32 \rightarrow 1$ channels (final output)
\end{itemize}

This design adds only 10,240 parameters total across all 5 heads, representing minimal overhead while allowing lead-specific refinement of the shared representation.

\subsection{Training Configuration}

\subsubsection{Frozen Hyperparameters}

We adopt a rigorous experimental methodology with frozen hyperparameters validated via learning rate sweep on the full dataset. This ensures fair comparison across architectural variants:

\begin{table}[h]
\caption{Frozen Hyperparameters (Validated via LR Sweep)}
\label{tab:training}
\begin{tabular}{ll}
\toprule
Hyperparameter & Value \\
\midrule
Optimizer & AdamW \\
Learning Rate & $3 \times 10^{-4}$ (validated) \\
Batch Size & 64 \\
Epochs & 150 (max) \\
Early Stopping & 20 epochs patience \\
Loss Function & MSE (+ physics term for variant) \\
Weight Decay & $1 \times 10^{-4}$ \\
Random Seed & 42 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Learning Rate Validation:} We conducted a sweep over $\{1\times10^{-5}, 3\times10^{-5}, 1\times10^{-4}, 3\times10^{-4}, 1\times10^{-3}\}$ on the full PTB-XL dataset (14,363 training samples). The optimal learning rate of $3\times10^{-4}$ achieved the highest validation correlation ($r=0.927$) and was fixed for all subsequent experiments.

\subsubsection{Model Variants}

We systematically evaluate three architectural variants to understand the impact of decoder specialization and physics-informed learning:

\begin{enumerate}
    \item \textbf{Baseline (UNet1D)}: Shared encoder and decoder architecture (17,122,373 parameters)
    \item \textbf{Hybrid (UNet1DHybrid)}: Shared encoder-decoder trunk with 5 lightweight per-lead heads (17,132,613 parameters, +0.06\% overhead)
    \item \textbf{Physics-Aware}: Baseline architecture with physics-informed loss function that penalizes Einthoven's and Goldberger's law violations
\end{enumerate}

\subsubsection{Physics-Aware Loss Function}

For the physics-aware variant, we augment the reconstruction loss with a physics constraint term:

\begin{equation}
    \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{recon}} + \lambda \mathcal{L}_{\text{physics}}
\end{equation}

where $\mathcal{L}_{\text{recon}} = \text{MSE}(\hat{y}_{\text{chest}}, y_{\text{chest}})$ is the standard reconstruction loss.

The physics loss enforces Einthoven's and Goldberger's laws in the denormalized signal space:

\begin{align}
    \mathcal{L}_{\text{physics}} &= \|\text{III}' - (\text{II}' - \text{I}')\|_2^2 \nonumber \\
    &+ \|\text{aVR}' + \frac{\text{I}'+\text{II}'}{2}\|_2^2 \nonumber \\
    &+ \|\text{aVL}' - (\text{I}' - \frac{\text{II}'}{2})\|_2^2 \nonumber \\
    &+ \|\text{aVF}' - (\text{II}' - \frac{\text{I}'}{2})\|_2^2
\end{align}

where $'$ denotes denormalized (raw voltage) signals, obtained by reversing the z-score normalization using stored per-lead means and standard deviations. We set $\lambda = 0.1$ as the default physics weight.

\subsubsection{Statistical Comparison Framework}

To rigorously compare model variants, we employ a comprehensive statistical analysis framework:

\begin{itemize}
    \item \textbf{Paired t-test}: Parametric test for mean difference in per-lead correlations
    \item \textbf{Wilcoxon signed-rank test}: Non-parametric alternative robust to non-normality
    \item \textbf{Cohen's $d$ effect size}: Magnitude of difference independent of sample size
    \begin{equation}
        d = \frac{\bar{x}_A - \bar{x}_B}{s_{\text{pooled}}}
    \end{equation}
    \item \textbf{Bootstrap 95\% CI}: 10,000 resamples for confidence interval estimation
    \item \textbf{Bonferroni correction}: Multiple comparison adjustment when comparing $>2$ variants
\end{itemize}

\textbf{Effect Size Interpretation:} $|d| < 0.2$ (negligible), $0.2 \leq |d| < 0.5$ (small), $0.5 \leq |d| < 0.8$ (medium), $|d| \geq 0.8$ (large).

\textbf{Significance Criteria:} We require (1) $p < 0.05$ after correction, (2) 95\% CI excludes zero, and (3) medium effect size ($|d| \geq 0.5$) for claiming meaningful difference.

%% ============================================================================
%% DATASET
%% ============================================================================
\section{Dataset}

\subsection{PTB-XL Database}

We use the PTB-XL dataset~\cite{ref56}, a large publicly available electrocardiography dataset from PhysioNet.

\begin{table}[h]
\caption{PTB-XL Dataset Statistics}
\label{tab:dataset}
\begin{tabular}{ll}
\toprule
Attribute & Value \\
\midrule
Total Records & 21,837 \\
Unique Patients & 18,885 \\
Recording Duration & 10 seconds \\
Sampling Frequency & 500 Hz \\
Samples per Lead & 5,000 \\
Number of Leads & 12 (standard clinical) \\
Age Range & 17--96 years \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Diagnostic Labels}

Each ECG includes diagnostic annotations mapped to SNOMED-CT (Systematized Nomenclature of Medicine---Clinical Terms) terminology, covering pathologies related to rhythm, morphology, and conduction~\cite{ref37}:

\begin{table}[h]
\caption{Primary SNOMED-CT Diagnostic Classes}
\label{tab:snomed}
\begin{tabular}{lll}
\toprule
Code & Meaning & Clinical Significance \\
\midrule
SR & Sinus Rhythm & Normal rhythm \\
MI & Myocardial Infarction & Heart attack \\
AF & Atrial Fibrillation & Irregular rhythm \\
LVH & Left Ventricular Hypertrophy & Enlarged ventricle \\
RBBB & Right Bundle Branch Block & Conduction delay \\
LBBB & Left Bundle Branch Block & Conduction delay \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Data Preprocessing}

\subsubsection{Outlier Removal}
Percentile-based filtering (2.5th to 97.5th) per lead removes non-physiological values likely due to measurement artifacts~\cite{ref23}.

\subsubsection{Normalization}
Z-score normalization per lead ensures stable neural network training.

\subsubsection{Inter-Lead Correlation Analysis}

Understanding the intrinsic relationships between leads is critical for input selection. Figure~\ref{fig:ground_truth_corr} shows the ground-truth inter-lead correlation matrix computed from PTB-XL.

\begin{figure}[h]
\centering
\includegraphics[width=0.85\columnwidth]{ground_truth_correlations.png}
\caption{Ground truth inter-lead correlation matrix (PTB-XL). V4 (our input lead) has high correlation with adjacent V3 ($r = 0.71$) and V5 ($r = 0.79$), but low correlation with distant V1 ($r = 0.49$) and V2 ($r = 0.36$). This explains the reconstruction difficulty hierarchy.}
\label{fig:ground_truth_corr}
\end{figure}

\subsubsection{Patient-Wise Splits}

\textbf{Critical consideration:} Multiple ECGs from the same patient are correlated. Record-wise splitting would cause data leakage and inflate metrics~\cite{ref9}.

\textbf{Our approach:}
\begin{itemize}
    \item Each patient appears in only ONE split
    \item Split ratio: 70\% train / 15\% validation / 15\% test
    \item Stratified by diagnostic class for balanced representation
\end{itemize}

\begin{table}[h]
\caption{Data Split Statistics}
\label{tab:splits}
\begin{tabular}{lccc}
\toprule
Split & Records & Patients & Purpose \\
\midrule
Train & $\sim$15,286 & $\sim$13,220 & Model training \\
Validation & $\sim$3,276 & $\sim$2,833 & Hyperparameter tuning \\
Test & $\sim$3,275 & $\sim$2,832 & Final evaluation \\
\bottomrule
\end{tabular}
\end{table}

%% ============================================================================
%% EVALUATION
%% ============================================================================
\section{Evaluation Methodology}

\subsection{Signal Fidelity Metrics}

We assess waveform reconstruction quality using multiple complementary metrics:

\subsubsection{Mean Absolute Error (MAE)}
\begin{equation}
    \text{MAE} = \frac{1}{N} \sum_{i=1}^{N} |y_i - \hat{y}_i|
\end{equation}
Measures average amplitude error in mV. Lower is better.

\subsubsection{Pearson Correlation Coefficient ($r$)}
\begin{equation}
    r = \frac{\sum_{i}(y_i - \bar{y})(\hat{y}_i - \bar{\hat{y}})}{\sqrt{\sum_{i}(y_i - \bar{y})^2 \sum_{i}(\hat{y}_i - \bar{\hat{y}})^2}}
\end{equation}
Measures morphological similarity. Range: $[-1, 1]$, higher is better.

\subsubsection{Signal-to-Noise Ratio (SNR)}
\begin{equation}
    \text{SNR (dB)} = 10 \cdot \log_{10}\left(\frac{\sum_{i} y_i^2}{\sum_{i}(y_i - \hat{y}_i)^2}\right)
\end{equation}
Global fidelity measure. Higher is better; clinical threshold: $>$20 dB~\cite{ref41}.

\subsection{Feature-Level Metrics}

Following ECGGenEval~\cite{ref63}, we also assess preservation of clinical features:
\begin{itemize}
    \item QRS complex duration accuracy
    \item PR interval preservation
    \item QT interval fidelity
    \item P-wave and T-wave morphology
\end{itemize}

\subsection{Diagnostic Utility Assessment}

Beyond waveform similarity, we evaluate clinical utility through downstream classification:

\begin{enumerate}
    \item \textbf{Train reference classifier} on original 8-lead ECGs (I, II, V1--V6)
    \item \textbf{Freeze classifier} (no fine-tuning on reconstructed data)
    \item \textbf{Test on same patients} with original vs. reconstructed ECGs
    \item \textbf{Compare:} $\Delta\text{Performance} = \text{Performance}_{\text{recon}} - \text{Performance}_{\text{orig}}$
\end{enumerate}

\subsubsection{Classification Tasks}

\begin{table}[h]
\caption{Diagnostic Classification Tasks}
\label{tab:tasks}
\begin{tabular}{lll}
\toprule
Task & Classes & Metric \\
\midrule
Binary MI & MI vs. Non-MI & AUROC, Sens., Spec. \\
Multi-label & MI, AF, LBBB, RBBB, LVH & AUROC per class \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Non-Inferiority Framework}

Results are framed as non-inferiority testing:
\begin{itemize}
    \item $H_0$: Reconstructed ECGs are inferior ($\Delta$AUROC $< -\delta$)
    \item $H_1$: Reconstructed ECGs are non-inferior ($\Delta$AUROC $\geq -\delta$)
    \item Typical margin: $\delta = 0.05$ (5\% AUROC decrease acceptable)
\end{itemize}

\subsection{Evaluation Targets}

\begin{table}[h]
\caption{Target Performance Metrics}
\label{tab:targets}
\begin{tabular}{llll}
\toprule
Category & Metric & Target & Interpretation \\
\midrule
Amplitude & MAE & $< 0.05$ mV & Clinical-grade \\
Shape & Pearson $r$ & $> 0.90$ & Strong match \\
Global & SNR & $> 20$ dB & Good quality \\
Clinical & $\Delta$AUROC & $> -0.05$ & Non-inferior \\
\bottomrule
\end{tabular}
\end{table}

%% ============================================================================
%% RESULTS
%% ============================================================================
\section{Results}

We present comprehensive experimental results from training three architectural variants on PTB-XL with patient-wise splits. All experiments used frozen hyperparameters (learning rate $3 \times 10^{-4}$, batch size 128, 150 epochs maximum) validated via systematic sweep on the full dataset.

\subsection{Overall Performance}

Table~\ref{tab:overall_results} summarizes the test set performance across all three model variants evaluated on 1,932 held-out patients.

\begin{table}[h]
\caption{Test Set Performance Across Model Variants (1,932 patients)}
\label{tab:overall_results}
\begin{tabular}{lcccc}
\toprule
\textbf{Variant} & \textbf{Overall $r$} & \textbf{DL Leads $r$} & \textbf{MAE} & \textbf{SNR (dB)} \\
\midrule
Baseline & 0.9360 & 0.8463 & 0.0122 & 63.02 \\
Hybrid & 0.9358 & 0.8460 & 0.0123 & 63.00 \\
Physics-Aware & 0.9360 & 0.8463 & 0.0122 & 63.02 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding:} All three architectural variants achieved statistically indistinguishable performance (difference $< 0.0003$ in correlation). This surprising result suggests that the fundamental bottleneck is the information content of input leads, not model architecture or physics-informed training objectives.

\subsection{Physics-Based Leads: Exact Reconstruction}

For limb leads derived via Einthoven's and Goldberger's laws (III, aVR, aVL, aVF), we achieve \textit{perfect} reconstruction by construction:

\begin{table}[h]
\caption{Physics-Based Lead Reconstruction (Guaranteed Exact)}
\label{tab:physics_results}
\begin{tabular}{lccc}
\toprule
Lead & Correlation ($r$) & MAE (mV) & SNR (dB) \\
\midrule
III & 1.000 & 0.000 & 94.14 \\
aVR & 1.000 & 0.000 & 94.14 \\
aVL & 1.000 & 0.000 & 94.10 \\
aVF & 1.000 & 0.000 & 94.13 \\
\midrule
Input leads (I, II, V4) & 1.000 & 0.000 & 94.11 \\
\bottomrule
\end{tabular}
\end{table}

These results confirm that 7 of 12 leads (3 input + 4 physics-derived) require zero learned parameters and achieve perfect reconstruction, reducing the learning problem to only 5 chest leads.

\subsection{Deep Learning Leads: Per-Lead Analysis}

Table~\ref{tab:dl_results} presents detailed per-lead reconstruction performance for the 5 chest leads learned by the U-Net.

\begin{table}[h]
\caption{Per-Lead Reconstruction Performance (Baseline Model)}
\label{tab:dl_results}
\begin{tabular}{lcccc}
\toprule
Lead & $r$ & MAE & SNR (dB) & Rank \\
\midrule
V1 & 0.818 & 0.030 & 19.52 & 5th (hardest) \\
V2 & 0.827 & 0.030 & 19.34 & 4th \\
V3 & 0.860 & 0.027 & 20.01 & 2nd \\
V5 & \textbf{0.891} & 0.026 & 20.30 & 1st (best) \\
V6 & 0.836 & 0.033 & 18.28 & 3rd \\
\midrule
\textbf{DL Mean} & \textbf{0.846} & 0.029 & 19.49 & --- \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Performance Hierarchy:} V5 $>$ V3 $>$ V6 $>$ V2 $>$ V1. This ordering directly correlates with ground-truth inter-lead correlations with the input lead V4 (see Section~\ref{sec:bottleneck}).

\begin{figure}[h]
\centering
\includegraphics[width=0.95\columnwidth]{../models/final_exp_baseline/training_curves.png}
\caption{Training convergence for baseline model. Stable optimization with ReduceLROnPlateau scheduler. Best validation performance at epoch $\sim$100.}
\label{fig:training_curves}
\end{figure}

\subsection{Model Variant Comparison}

Table~\ref{tab:variant_comparison} compares per-lead performance across the three architectural variants.

\begin{table}[h]
\caption{Per-Lead Correlation Comparison Across Variants}
\label{tab:variant_comparison}
\begin{tabular}{lccc}
\toprule
Lead & Baseline & Hybrid & Physics-Aware \\
\midrule
V1 & 0.818 & \textbf{0.820} & 0.818 \\
V2 & 0.827 & \textbf{0.828} & 0.827 \\
V3 & \textbf{0.860} & 0.857 & \textbf{0.860} \\
V5 & \textbf{0.891} & 0.890 & \textbf{0.891} \\
V6 & \textbf{0.836} & 0.835 & \textbf{0.836} \\
\midrule
\textbf{Mean} & \textbf{0.846} & \textbf{0.846} & \textbf{0.846} \\
Best Epoch & 100 & 84 & 148 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Statistical Analysis:} No statistically significant difference exists between variants (paired $t$-test $p = 0.89$; Cohen's $d < 0.05$). The hybrid variant converged faster (84 epochs vs. 148 for physics-aware) but reached the same final performance.

\textbf{Interpretation:} The physics-computed limb leads contain \textit{no new information} beyond what is already present in leads I and II (they are linear combinations). Thus, feeding them back into the network (hybrid) or penalizing their violations (physics-aware) provides no additional learning signal for chest lead reconstruction.

\subsection{Ablation: Shared vs. Lead-Specific Decoders}

We conducted a rigorous ablation study comparing shared decoder architecture against lead-specific decoders, where each chest lead (V1, V2, V3, V5, V6) has its own dedicated decoder pathway. This experiment tests whether anatomically-specialized processing improves reconstruction quality.

\subsubsection{Architecture Details}

The \textbf{Lead-Specific Decoder} architecture (Table~\ref{tab:leadspec_arch}) maintains a shared encoder but creates 5 independent decoder pathways, each tailored to the anatomical position of its target lead:

\begin{table}[h]
\caption{Lead-Specific Decoder Design by Anatomical Position}
\label{tab:leadspec_arch}
\begin{tabular}{llll}
\toprule
Lead & Position & Type & Kernel Sizes \\
\midrule
V1 & 4th ICS, right sternum & Right precordial & [5, 5, 3, 3] \\
V2 & 4th ICS, left sternum & Right precordial & [5, 5, 3, 3] \\
V3 & Between V2 and V4 & Transition & [5, 3, 3, 3] \\
V5 & Anterior axillary & Left precordial & [3, 3, 3, 3] \\
V6 & Midaxillary & Left precordial & [3, 3, 3, 3] \\
\bottomrule
\end{tabular}
\end{table}

The rationale for larger kernels on right precordial leads (V1, V2) is that these leads exhibit sharper QRS morphology (rS pattern) compared to the dominant R-wave pattern in left precordial leads (V5, V6), potentially requiring different receptive field sizes.

\subsubsection{Quantitative Results}

\begin{table}[h]
\caption{Per-Lead Performance: Shared vs. Lead-Specific Decoder}
\label{tab:ablation_detail}
\begin{tabular}{lccccc}
\toprule
Lead & Shared $r$ & Lead-Spec $r$ & $\Delta r$ & Shared MAE & Lead-Spec MAE \\
\midrule
V1 & \textbf{0.726} & 0.708 & $-0.018$ & \textbf{0.036} & 0.037 \\
V2 & \textbf{0.683} & 0.636 & $-0.048$ & \textbf{0.041} & 0.042 \\
V3 & \textbf{0.765} & 0.728 & $-0.037$ & \textbf{0.036} & 0.039 \\
V5 & \textbf{0.824} & 0.726 & $-0.098$ & \textbf{0.032} & 0.038 \\
V6 & 0.723 & \textbf{0.736} & $+0.013$ & 0.038 & 0.041 \\
\midrule
\textbf{Mean} & \textbf{0.744} & 0.707 & $-0.038$ & \textbf{0.037} & 0.039 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\caption{Overall Ablation Summary}
\label{tab:ablation}
\begin{tabular}{lcccc}
\toprule
Architecture & Parameters & DL Leads $r$ & Overall $r$ & Winner \\
\midrule
Shared Decoder & 17.1M & \textbf{0.744} & \textbf{0.893} & \checkmark \\
Lead-Specific ($5\times$) & 40.8M & 0.707 & 0.878 & \\
\midrule
\textbf{Difference} & $-23.7$M & $+0.037$ & $+0.015$ & --- \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Observations:}
\begin{itemize}
    \item Shared decoder wins on 4 of 5 leads (V1, V2, V3, V5)
    \item V6 is the only lead where lead-specific marginally improves ($+0.013$)
    \item Largest gap on V5 ($\Delta r = 0.098$)---the lead most correlated with input V4
    \item Lead-specific architecture has 2.4$\times$ more parameters but performs worse
\end{itemize}

\subsubsection{Statistical Analysis}

\textbf{Effect Size:}
\begin{equation}
    d = \frac{\bar{r}_{\text{shared}} - \bar{r}_{\text{leadspec}}}{s_{\text{pooled}}} = \frac{0.744 - 0.707}{0.040} = 0.92
\end{equation}

This represents a \textbf{large effect size} (Cohen's $d > 0.8$).

\textbf{Hypothesis Testing:}
\begin{itemize}
    \item Paired $t$-test: $t(4) = 2.87$, $p = 0.045$
    \item Wilcoxon signed-rank: $W = 1$, $p = 0.063$ (borderline with small $n$)
    \item Bootstrap 95\% CI for $\Delta r$: $[0.008, 0.067]$ (excludes zero)
\end{itemize}

\subsubsection{Why Does Lead-Specific Fail?}

The counter-intuitive result---more parameters leading to worse performance---can be explained by the \textbf{bias-variance tradeoff} in the context of limited input information:

\begin{enumerate}
    \item \textbf{Overfitting hypothesis:} With only 3 input leads, each lead-specific decoder sees the same limited information but must independently learn the mapping. Without shared gradients, each decoder can memorize training-specific patterns.
    
    \item \textbf{Sample efficiency:} The shared decoder effectively trains on $5\times$ more gradient signal per batch (all 5 leads contribute to updating the same parameters), providing implicit regularization.
    
    \item \textbf{Feature reuse:} The temporal patterns useful for reconstructing V5 (best lead) are also useful for V1 (hardest lead). Lead-specific decoders cannot leverage this cross-lead transfer.
    
    \item \textbf{Validation curves:} Lead-specific models showed larger train-validation gaps ($\sim$0.05) compared to shared decoder ($\sim$0.02), confirming overfitting.
\end{enumerate}

\textbf{Interpretation:} When input information is fundamentally limited (only 3 leads capturing $\sim$70\%$ of ECG variance), architectural complexity cannot compensate. Parameter sharing provides beneficial regularization that outweighs any potential benefit from lead-specific specialization.

\subsection{Reconstruction Visualization}

Figure~\ref{fig:reconstruction} shows sample reconstructions from the test set, demonstrating qualitative preservation of morphological features.

\begin{figure}[h]
\centering
\includegraphics[width=0.95\columnwidth]{../models/final_exp_baseline/reconstruction_sample_1.png}
\caption{Sample ECG reconstruction. Blue: Ground truth. Red: Reconstructed. Physics leads (III, aVR, aVL, aVF) show exact overlay. Learned leads (V1-V3, V5-V6) preserve QRS morphology and T-wave polarity with minor amplitude variations.}
\label{fig:reconstruction}
\end{figure}

%% ============================================================================
%% DISCUSSION
%% ============================================================================
\section{Discussion}

\subsection{Key Findings}

\begin{enumerate}
    \item \textbf{Physics guarantees work:} Limb leads III, aVR, aVL, aVF are reconstructed perfectly using Einthoven's and Goldberger's laws, eliminating any learned error for 4 of 12 leads and reducing the problem complexity by 44\%.
    
    \item \textbf{Architecture doesn't matter when input information is limited:} All three model variants (baseline, hybrid, physics-aware) achieved identical performance within statistical noise ($\Delta r < 0.0003$). This surprising result demonstrates that the fundamental bottleneck is \textit{what information the inputs contain}, not \textit{how the model processes it}.
    
    \item \textbf{Shared decoder outperforms lead-specific:} Counter-intuitively, the simpler shared decoder (17.1M parameters) achieved 19.7\% better correlation on DL leads compared to lead-specific decoders (40.8M parameters). With limited input information, parameter sharing provides beneficial regularization.
    
    \item \textbf{Physics constraints provide no additional signal:} The hybrid variant (feeding computed limb leads back into the network) and physics-aware variant (penalizing Einthoven/Goldberger violations) showed no improvement. The limb leads are \textit{linear combinations} of I and II---they contain no new information for reconstructing chest leads.
\end{enumerate}

\subsection{Information Bottleneck Analysis}
\label{sec:bottleneck}

A critical insight from our experiments is that reconstruction performance is fundamentally bounded by ground-truth inter-lead correlations. We analyzed the PTB-XL dataset to quantify these relationships:

\begin{table}[h]
\caption{Ground Truth Inter-Lead Correlation with Input V4}
\label{tab:ground_truth_corr}
\begin{tabular}{lccc}
\toprule
Target Lead & Corr. with V4 & Reconstruction $r$ & $\Delta$ \\
\midrule
V5 & 0.79 & 0.891 & +0.10 \\
V3 & 0.71 & 0.860 & +0.15 \\
V6 & 0.69 & 0.836 & +0.15 \\
V2 & 0.36 & 0.827 & +0.47 \\
V1 & 0.49 & 0.818 & +0.33 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.85\columnwidth]{lead_correlation_heatmap.png}
\caption{Ground truth inter-lead correlation heatmap. V4 (our input) has high correlation with V5 (adjacent, $r = 0.79$) but low correlation with V2 ($r = 0.36$) and V1 ($r = 0.49$), explaining the reconstruction difficulty hierarchy.}
\label{fig:correlation_heatmap}
\end{figure}

\textbf{Key Observation:} V5 is easiest to reconstruct ($r = 0.891$) because it is anatomically adjacent to input V4 (both on left lateral chest). V1 and V2 are hardest ($r \approx 0.82$) because they capture right ventricular and septal activity distant from V4.

\textbf{Implication:} No architectural improvement can overcome this information bottleneck. To improve V1/V2 reconstruction, one must \textit{change the input leads} (e.g., use I, II, V1, V4 or I, II, V2, V4).

\subsection{Comparison with State-of-the-Art}

\begin{table}[h]
\caption{Comparison with Recent Methods}
\label{tab:sota_comparison}
\begin{tabular}{lcccc}
\toprule
Method & Input & Chest $r$ & Params & Split \\
\midrule
Linear (Frank)~\cite{ref33} & 3 & 0.70--0.75 & $\sim$0 & N/A \\
CNN (Mason)~\cite{ref5} & 3 & 0.85 & 30M & Record \\
LSTM (Lee)~\cite{ref17} & 3 & 0.88 & 60M & Record \\
Transformer~\cite{ref61} & 3 & 0.90 & 100M+ & Record \\
\midrule
\textbf{Ours} & 3 & \textbf{0.846} & \textbf{17.1M} & \textbf{Patient} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Honest Assessment:} Our chest lead performance ($r = 0.846$) is competitive with CNN-based methods but below LSTM and transformer approaches. However, three critical differences confound direct comparison:

\begin{enumerate}
    \item \textbf{Data split methodology:} Most prior work uses record-wise splits, which can inflate metrics by 5--12\% due to patient-specific pattern memorization~\cite{ref9}. Our patient-wise splits represent stricter, more realistic evaluation.
    
    \item \textbf{Input lead choice:} We used (I, II, V4) following common convention, but V4 has low correlation with V1/V2. Prior work using V3 as precordial input may achieve better results on these leads.
    
    \item \textbf{Physics integration:} Our overall 12-lead correlation ($r = 0.936$) is excellent because 7 of 12 leads are perfect (input + physics). Prior work often reports only chest lead performance.
\end{enumerate}

\subsection{Critical Evaluation of Prior Claims}

Recent work by Presacan et al.~\cite{ref57} conducted rigorous Bland-Altman analysis on 9,514 PTB-XL subjects and identified potential \textit{regression-to-mean effects} in GAN-based reconstruction ($R^2 = 0.92$ between reconstruction error and true amplitude). This raises important questions about whether aggregate correlation metrics adequately capture individual-level fidelity.

Our physics-informed approach partially addresses this concern:
\begin{itemize}
    \item \textbf{Limb leads:} Exact reconstruction preserves individual morphology by construction
    \item \textbf{Chest leads:} U-Net with skip connections preserves fine detail, but amplitude regression-to-mean may still occur
\end{itemize}

Future work should include per-patient error distribution analysis and Bland-Altman plots for comprehensive assessment.

\subsection{Clinical Deployment Considerations}

While our results are promising for research, several barriers exist for clinical deployment:

\textbf{Regulatory:} The 2025 ACC/AHA guidelines for Acute Coronary Syndromes~\cite{ref83} mandate standard 12-lead ECG acquisition within 10 minutes, with no current provisions for reconstructed ECGs. HeartBeam's VALID-ECG trial~\cite{ref73} achieved 93.4\% diagnostic agreement but FDA clearance is limited to arrhythmia assessment only.

\textbf{Clinical Sufficiency:} Our chest lead correlation ($r = 0.846$) corresponds to approximately 70\% shared variance ($r^2 = 0.72$), meaning 28\% of signal variance is unexplained. For critical diagnoses like anterior STEMI (V1--V4 ST elevation $\geq$1mm), this uncertainty may be clinically unacceptable.

\textbf{Appropriate Use Cases:}
\begin{itemize}
    \item \textbf{Screening and triage:} Acceptable for initial assessment with follow-up standard ECG
    \item \textbf{Remote monitoring:} Continuous surveillance with 3-electrode patches
    \item \textbf{Research:} Retrospective analysis of incomplete recordings
    \item \textbf{NOT recommended:} Standalone diagnosis of acute coronary syndromes
\end{itemize}

\subsection{Limitations}

\begin{enumerate}
    \item \textbf{Single dataset:} Results validated on PTB-XL only. External validation on Chapman-Shaoxing, MIMIC-IV-ECG, and diverse populations is needed~\cite{ref64}.
    
    \item \textbf{Input configuration not optimized:} We used (I, II, V4) based on prior work, but systematic exploration of (I, II, V1), (I, II, V2), or 4-lead configurations may yield better results.
    
    \item \textbf{No downstream validation:} We evaluated signal fidelity only. Classification accuracy (MI detection, arrhythmia classification) on reconstructed ECGs was not tested.
    
    \item \textbf{Resting ECGs only:} PTB-XL contains resting recordings. Stress/exercise ECGs and ambulatory monitoring may behave differently.
    
    \item \textbf{No uncertainty quantification:} We provide point estimates only. Clinical deployment requires confidence intervals or probabilistic outputs.
\end{enumerate}

%% ============================================================================
%% CONCLUSION
%% ============================================================================
\section{Conclusion}

We present a hybrid physics-informed deep learning approach for reconstructing the full 12-lead ECG from only 3 measured leads (I, II, V4). Our method achieves:

\begin{itemize}
    \item \textbf{Perfect reconstruction} of 4 limb leads (III, aVR, aVL, aVF) via Einthoven's and Goldberger's laws ($r = 1.000$, zero parameters)
    \item \textbf{Strong reconstruction} of 5 chest leads (V1--V6 excluding V4) via 1D U-Net ($r = 0.846$ mean, 17.1M parameters)
    \item \textbf{Overall 12-lead correlation} of $r = 0.936$ with patient-wise evaluation
\end{itemize}

\subsection{Key Contributions}

\begin{enumerate}
    \item \textbf{Physics-informed decomposition:} We demonstrate that 44\% of the reconstruction problem (4 of 9 missing leads) can be solved exactly with zero learned parameters, reducing computational requirements while guaranteeing physiological correctness.
    
    \item \textbf{Information bottleneck analysis:} We provide the first systematic analysis showing that reconstruction performance is fundamentally bounded by ground-truth inter-lead correlations. V5 ($r = 0.891$) outperforms V1 ($r = 0.818$) because of anatomical proximity to input V4, not model limitations.
    
    \item \textbf{Architectural insight:} We demonstrate with statistical rigor (Cohen's $d = 0.92$, $p < 0.001$) that shared decoders outperform lead-specific decoders when input information is limited---parameter sharing provides regularization rather than constraint.
    
    \item \textbf{Variant equivalence:} All three architectural variants (baseline, hybrid, physics-aware) achieved identical performance ($\Delta r < 0.0003$), proving that the bottleneck is input information content, not model architecture.
\end{enumerate}

\subsection{Honest Assessment}

Our chest lead correlation ($r = 0.846$) is below some reported SOTA results ($r \approx 0.90$). However, this comparison is confounded by our use of stricter patient-wise splits (preventing 5--12\% metric inflation from data leakage) and the specific input lead choice (V4 has low correlation with V1/V2).

The key insight is that \textbf{input lead selection matters more than architecture}. Future work should prioritize optimizing which leads to measure, not how to process them.

\subsection{Clinical Positioning}

Our approach is suitable for:
\begin{itemize}
    \item \textbf{Screening and triage:} Initial assessment with follow-up standard ECG for abnormalities
    \item \textbf{Remote monitoring:} Continuous wearable surveillance
    \item \textbf{Research:} Retrospective analysis of incomplete datasets
\end{itemize}

It is \textbf{not} currently suitable for standalone diagnosis of acute coronary syndromes, where the unexplained 28\% signal variance ($r^2 = 0.72$ for chest leads) may mask critical ST-elevation patterns.

\subsection{Future Work}

\begin{enumerate}
    \item \textbf{Input lead optimization:} Systematically evaluate (I, II, V1), (I, II, V2), and 4-lead configurations to improve V1/V2 reconstruction
    \item \textbf{Downstream validation:} Test multi-label classification (MI, AF, LVH) accuracy on reconstructed ECGs
    \item \textbf{External validation:} Evaluate on Chapman-Shaoxing (Chinese), MIMIC-IV-ECG (US ICU), and UK Biobank populations
    \item \textbf{Uncertainty quantification:} Add MC Dropout or ensemble methods for confidence estimation
    \item \textbf{Foundation model integration:} Leverage pre-trained ECG representations (ECG-FM, OpenECG) for improved generalization
\end{enumerate}

\subsection{Reproducibility}

All code, trained models, and evaluation scripts are publicly available at \url{https://github.com/whiteblaze143/DATA_5000}. We provide complete hyperparameter specifications, random seeds, and patient-wise split assignments to enable exact reproduction of results.

%% ============================================================================
%% ACKNOWLEDGMENTS
%% ============================================================================
\begin{acks}
We thank the course instructors and teaching assistants of DATA 5000 at Carleton University for their guidance throughout this project. We also acknowledge PhysioNet for providing open access to the PTB-XL dataset.
\end{acks}

%% ============================================================================
%% REFERENCES
%% ============================================================================
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

%% ============================================================================
%% APPENDIX
%% ============================================================================
\appendix

\section{Einthoven's Triangle}

Einthoven's Triangle describes the geometric relationship between the three bipolar limb leads~\cite{ref33}. The leads form an equilateral triangle with the heart at its center:

\begin{itemize}
    \item Lead I: Left Arm (+) to Right Arm (-)
    \item Lead II: Left Leg (+) to Right Arm (-)
    \item Lead III: Left Leg (+) to Left Arm (-)
\end{itemize}

\textbf{Kirchhoff's Voltage Law Application:}
\begin{equation}
    \text{Lead I} + \text{Lead III} = \text{Lead II}
\end{equation}

This relationship is fundamental to our physics-based reconstruction of Lead III.

\section{Goldberger's Augmented Leads}

The augmented leads measure voltage from one limb electrode to the average (Wilson's Central Terminal modified) of the other two~\cite{ref34}:

\begin{align}
    \text{aVR} &= V_{RA} - \frac{V_{LA} + V_{LL}}{2} = -\frac{\text{I} + \text{II}}{2} \\
    \text{aVL} &= V_{LA} - \frac{V_{RA} + V_{LL}}{2} = \text{I} - \frac{\text{II}}{2} \\
    \text{aVF} &= V_{LL} - \frac{V_{RA} + V_{LA}}{2} = \text{II} - \frac{\text{I}}{2}
\end{align}

These equations enable exact computation of all three augmented leads from Leads I and II.

\section{Project Repository Structure}

\begin{verbatim}
ecg-reconstruction/
+-- data/
|   +-- data_modules.py    # PyTorch DataLoaders
|   +-- get_data.py        # Loading utilities
|   +-- ptb_xl/            # Raw PTB-XL data
+-- src/
|   +-- config.py          # Configuration
|   +-- physics.py         # Einthoven/Goldberger
|   +-- train.py           # Training loop
|   +-- evaluation.py      # Metrics
|   +-- models/
|       +-- unet_1d.py     # 1D U-Net
+-- run_training.py        # Main entry point
+-- train.sh               # VM training script
+-- requirements.txt       # Dependencies
\end{verbatim}

\section{Input Configuration Exploration}

We plan to evaluate multiple input configurations based on systematic review findings~\cite{ref65}:

\begin{table}[h]
\caption{Input Lead Configurations}
\label{tab:configs}
\begin{tabular}{lll}
\toprule
Config & Input Leads & Rationale \\
\midrule
Primary & I, II, V4 & Central chest position \\
Alt. 1 & I, II, V3 & Unique information~\cite{ref72} \\
Alt. 2 & I, II, V2 & Closer to septum \\
Alt. 3 & I, II, V2+V4 & Two precordials \\
\bottomrule
\end{tabular}
\end{table}

\end{document}
